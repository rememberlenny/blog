<!DOCTYPE html>
<html lang="en-US">
<head itemscope itemtype="https://schema.org/WebSite">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Writing from Lenny Bogdonoff &#x2d; Page 3 &#x2d; Writing online</title>
	<style>img:is([sizes="auto" i], [sizes^="auto," i]) { contain-intrinsic-size: 3000px 1500px }</style>
	<!-- Jetpack Site Verification Tags -->
<meta name="google-site-verification" content="5oW1yK7b9nqJ5K9xt0OHHbL72j56-atiXIgrHBR3zvQ">

<!-- The SEO Framework by Sybre Waaijer -->
<meta name="robots" content="max-snippet:-1,max-image-preview:standard,max-video-preview:-1">
<link rel="canonical" href="/page/3/">
<link rel="prev" href="/page/2/">
<link rel="next" href="/page/4/">
<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Remember Lenny">
<meta property="og:title" content="Writing from Lenny Bogdonoff &#x2d; Page 3">
<meta property="og:url" content="/page/3/">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@rememberlenny">
<meta name="twitter:title" content="Writing from Lenny Bogdonoff &#x2d; Page 3">
<meta name="google-site-verification" content="5oW1yK7b9nqJ5K9xt0OHHbL72j56-atiXIgrHBR3zvQ">
<script type="application/ld+json">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"/#/schema/WebSite","url":"/","name":"Remember Lenny","alternateName":"Lenny Bogdonoff","description":"Writing online","inLanguage":"en-US","potentialAction":{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"/search/{search_term_string}/"},"query-input":"required name=search_term_string"},"publisher":{"@type":"Person","@id":"/#/schema/Person","name":"Lenny Bogdonoff","url":"/"}},{"@type":"WebPage","@id":"/page/3/","url":"/page/3/","name":"Writing from Lenny Bogdonoff - Page 3 - Writing online","inLanguage":"en-US","isPartOf":{"@id":"/#/schema/WebSite"},"breadcrumb":{"@type":"BreadcrumbList","@id":"/#/schema/BreadcrumbList","itemListElement":{"@type":"ListItem","position":1,"name":"Remember Lenny"}},"about":{"@type":"Organization","@id":"/#/schema/Organization","name":"Lenny Bogdonoff","url":"/"}}]}</script>
<!-- / The SEO Framework by Sybre Waaijer | 0.66ms meta | 0.09ms boot -->

<link rel="dns-prefetch" href="//stats.wp.com">
<link rel="dns-prefetch" href="//fonts.googleapis.com">
<link rel="dns-prefetch" href="//c0.wp.com">
<link rel="dns-prefetch" href="//www.googletagmanager.com">
<link rel="dns-prefetch" href="//pagead2.googlesyndication.com">
<link rel="alternate" type="application/rss+xml" title="Remember Lenny &raquo; Feed" href="/feed/">
<link rel="alternate" type="application/rss+xml" title="Remember Lenny &raquo; Comments Feed" href="/comments/feed/">
<script>
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/15.0.3\/svg\/","svgExt":".svg","source":{"concatemoji":"\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.7.1"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"üè≥Ô∏è‚Äç‚ößÔ∏è","üè≥Ô∏è‚Äã‚ößÔ∏è")?!1:!n(e,"üá∫üá≥","üá∫‚Äãüá≥")&&!n(e,"üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø","üè¥‚ÄãÛ†Åß‚ÄãÛ†Å¢‚ÄãÛ†Å•‚ÄãÛ†ÅÆ‚ÄãÛ†Åß‚ÄãÛ†Åø");case"emoji":return!n(e,"üê¶‚Äç‚¨õ","üê¶‚Äã‚¨õ")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
</script>
<link rel="stylesheet" id="atomic-blocks-fontawesome-css" href="/wp-content/plugins/atomic-blocks/dist/assets/fontawesome/css/all.min.css?ver=1734914581" media="all">
<link rel="stylesheet" id="genesis-sample-css" href="/wp-content/themes/genesis-sample/style.css?ver=3.2.0" media="all">
<style id="wp-emoji-styles-inline-css">img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}</style>
<link rel="stylesheet" id="wp-block-library-css" href="https://c0.wp.com/c/6.7.1/wp-includes/css/dist/block-library/style.min.css" media="all">
<link rel="stylesheet" id="atomic-blocks-style-css-css" href="/wp-content/plugins/atomic-blocks/dist/blocks.style.build.css?ver=1734914581" media="all">
<link rel="stylesheet" id="mediaelement-css" href="https://c0.wp.com/c/6.7.1/wp-includes/js/mediaelement/mediaelementplayer-legacy.min.css" media="all">
<link rel="stylesheet" id="wp-mediaelement-css" href="https://c0.wp.com/c/6.7.1/wp-includes/js/mediaelement/wp-mediaelement.min.css" media="all">
<style id="jetpack-sharing-buttons-style-inline-css">.jetpack-sharing-buttons__services-list{display:flex;flex-direction:row;flex-wrap:wrap;gap:0;list-style-type:none;margin:5px;padding:0}.jetpack-sharing-buttons__services-list.has-small-icon-size{font-size:12px}.jetpack-sharing-buttons__services-list.has-normal-icon-size{font-size:16px}.jetpack-sharing-buttons__services-list.has-large-icon-size{font-size:24px}.jetpack-sharing-buttons__services-list.has-huge-icon-size{font-size:36px}@media print{.jetpack-sharing-buttons__services-list{display:none!important}}.editor-styles-wrapper .wp-block-jetpack-sharing-buttons{gap:0;padding-inline-start:0}ul.jetpack-sharing-buttons__services-list.has-background{padding:1.25em 2.375em}</style>
<style id="classic-theme-styles-inline-css">/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}</style>
<style id="global-styles-inline-css">:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--theme-primary: #0073e5;--wp--preset--color--theme-secondary: #0073e5;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 12px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 20px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-size--normal: 18px;--wp--preset--font-size--larger: 24px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
:root :where(.wp-block-pullquote){font-size: 1.5em;line-height: 1.6;}</style>
<link rel="stylesheet" id="genesis-sample-fonts-css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro%3A400%2C400i%2C600%2C700&#038;display=swap&#038;ver=3.2.0" media="all">
<link rel="stylesheet" id="dashicons-css" href="https://c0.wp.com/c/6.7.1/wp-includes/css/dashicons.min.css" media="all">
<link rel="stylesheet" id="genesis-sample-gutenberg-css" href="/wp-content/themes/genesis-sample/lib/gutenberg/front-end.css?ver=3.2.0" media="all">
<style id="genesis-sample-gutenberg-inline-css">.ab-block-post-grid .ab-post-grid-items h2 a:hover {
	color: #0073e5;
}

.site-container .wp-block-button .wp-block-button__link {
	background-color: #0073e5;
}

.wp-block-button .wp-block-button__link:not(.has-background),
.wp-block-button .wp-block-button__link:not(.has-background):focus,
.wp-block-button .wp-block-button__link:not(.has-background):hover {
	color: #ffffff;
}

.site-container .wp-block-button.is-style-outline .wp-block-button__link {
	color: #0073e5;
}

.site-container .wp-block-button.is-style-outline .wp-block-button__link:focus,
.site-container .wp-block-button.is-style-outline .wp-block-button__link:hover {
	color: #2396ff;
}		.site-container .has-small-font-size {
			font-size: 12px;
		}		.site-container .has-normal-font-size {
			font-size: 18px;
		}		.site-container .has-large-font-size {
			font-size: 20px;
		}		.site-container .has-larger-font-size {
			font-size: 24px;
		}		.site-container .has-theme-primary-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-primary-color,
		.site-container .wp-block-button.is-style-outline .wp-block-button__link.has-theme-primary-color {
			color: #0073e5;
		}

		.site-container .has-theme-primary-background-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-primary-background-color,
		.site-container .wp-block-pullquote.is-style-solid-color.has-theme-primary-background-color {
			background-color: #0073e5;
		}		.site-container .has-theme-secondary-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-secondary-color,
		.site-container .wp-block-button.is-style-outline .wp-block-button__link.has-theme-secondary-color {
			color: #0073e5;
		}

		.site-container .has-theme-secondary-background-color,
		.site-container .wp-block-button .wp-block-button__link.has-theme-secondary-background-color,
		.site-container .wp-block-pullquote.is-style-solid-color.has-theme-secondary-background-color {
			background-color: #0073e5;
		}</style>
<link rel="stylesheet" id="simple-social-icons-font-css" href="/wp-content/plugins/simple-social-icons/css/style.css?ver=3.0.2" media="all">
<script src="https://c0.wp.com/c/6.7.1/wp-includes/js/jquery/jquery.min.js" id="jquery-core-js"></script>
<script src="https://c0.wp.com/c/6.7.1/wp-includes/js/jquery/jquery-migrate.min.js" id="jquery-migrate-js"></script>
<link rel="https://api.w.org/" href="/wp-json/">
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="/xmlrpc.php?rsd">
<meta name="generator" content="Site Kit by Google 1.139.0">	<style>img#wpstats{display:none}</style>
		<link rel="icon" href="/wp-content/themes/genesis-sample/images/favicon.ico">

<!-- Google AdSense meta tags added by Site Kit -->
<meta name="google-adsense-platform-account" content="ca-host-pub-2644536267352236">
<meta name="google-adsense-platform-domain" content="sitekit.withgoogle.com">
<!-- End Google AdSense meta tags added by Site Kit -->

<!-- Google AdSense snippet added by Site Kit -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3001221386572847&amp;host=ca-host-pub-2644536267352236" crossorigin="anonymous"></script>

<!-- End Google AdSense snippet added by Site Kit -->
		<style id="wp-custom-css">.site-inner img {
	max-width: 100%;
}</style>
		</head>
<body class="home blog paged wp-embed-responsive paged-3 header-full-width content-sidebar genesis-breadcrumbs-hidden genesis-footer-widgets-hidden" itemscope itemtype="https://schema.org/WebPage">
<div class="site-container">
<ul class="genesis-skip-link">
<li><a href="#genesis-nav-primary" class="screen-reader-shortcut"> Skip to primary navigation</a></li>
<li><a href="#genesis-content" class="screen-reader-shortcut"> Skip to main content</a></li>
<li><a href="#genesis-sidebar-primary" class="screen-reader-shortcut"> Skip to primary sidebar</a></li>
</ul>
<header class="site-header" itemscope itemtype="https://schema.org/WPHeader"><div class="wrap">
<div class="title-area">
<h1 class="site-title" itemprop="headline"><a href="/">Remember Lenny</a></h1>
<p class="site-description" itemprop="description">Writing online</p>
</div>
<nav class="nav-primary" aria-label="Main" itemscope itemtype="https://schema.org/SiteNavigationElement" id="genesis-nav-primary"><div class="wrap"><ul id="menu-header-menu" class="menu genesis-nav-menu menu-primary js-superfish">
<li id="menu-item-1666" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1666"><a href="https://rememberlenny.com/" itemprop="url"><span itemprop="name">Portfolio</span></a></li>
<li id="menu-item-1667" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1667"><a href="mailto:lkbgift@gmail.com" itemprop="url"><span itemprop="name">Email</span></a></li>
<li id="menu-item-1668" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1668"><a href="http://twitter.com/rememberlenny" itemprop="url"><span itemprop="name">Twitter</span></a></li>
<li id="menu-item-1669" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1669"><a href="https://www.linkedin.com/in/rememberlenny" itemprop="url"><span itemprop="name">LinkedIn</span></a></li>
<li id="menu-item-1670" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-1670"><a href="http://github.com/rememberlenny" itemprop="url"><span itemprop="name">Github</span></a></li>
</ul></div></nav>
</div></header><div class="site-inner"><div class="content-sidebar-wrap">
<main class="content" id="genesis-content"><article class="post-997 post type-post status-publish format-standard has-post-thumbnail category-uncategorized tag-orbital tag-reflection entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/12/06/goodbye-155-2/">Goodbye 155</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-12-06T17:14:28+00:00">December 6, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<figure class="wp-block-image alignfull"><img decoding="async" src="/wp-content/uploads/2020/03/img_5e65c0c95f678.jpg" alt=""></figure>



<p>Yesterday was the ‚ÄúGoodbye 155‚Äù celebrating the next steps for Orbital‚Äôs historic 155 Rivington St location. More than anything, the night felt more like the closing of a community church, and the gathering of its congregation. The evening was designed to provide space for people to share their experiences and lessons learned. It was very ‚ÄúGary‚Äù. I didn‚Äôt personally share anything, but took notes throughout the evening when I remembered long lost memories and weird experiences that made Orbital special to me.</p>



<div class="wp-block-image"><figure class="alignleft is-resized"><img decoding="async" src="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.26-PM.png" alt="" class="wp-image-1003" width="289" height="283" srcset="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.26-PM.png 920w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.26-PM-300x293.png 300w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.26-PM-768x751.png 768w" sizes="(max-width: 289px) 100vw, 289px"><figcaption> Gary and Christina possibly planning their 1K</figcaption></figure></div>



<p>First of all, I came across Gary through a seemingly unique set of events. I met Gary after being invited to co-work with him and Jed at a coffee shop in k-town, after lunch at a Korean restaurant. I had just met Jed in Florida at a JavaScript conference, and soon after saw him again in Berlin, when I decided to attend the sister conference the same year. To cowork together, Gary had a fascinating hotspot device, called the <a href="https://techcrunch.com/2015/11/05/karmas-mobile-hotspot-adds-neverstop-a-50-per-month-unlimited-data-plan/">Karma</a>, which touched on my tech virtues of interesting new gadgets.&nbsp;</p>



<div class="wp-block-image"><figure class="alignright is-resized"><img decoding="async" src="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-12.09.47-PM.png" alt="" class="wp-image-998" width="317" height="257" srcset="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-12.09.47-PM.png 515w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-12.09.47-PM-300x243.png 300w" sizes="(max-width: 317px) 100vw, 317px"><figcaption>Jed doing everything he can to hold back from singing &#8220;It&#8217;s So Hard To Say Goodbye To Yesterday&#8221; <a href="https://www.youtube.com/watch?v=-w6m-nhUcos">https://www.youtube.com/watch?v=-w6m-nhUcos</a></figcaption></figure></div>



<p>I got to learn more about Gary and <a href="https://postindustrialdesign.school/teach-the-1k/">the class</a> he was teaching at SVA, where students were tasked with making a product that create $1000 in revenue over one month. Fascinated by the idea, I kept in touch over email, trying to find out if I could audit the class or have him send me the materials. Eventually, this resulted in learning about Orbital and it‚Äôs first program to help provide a structure and space for people with side-projects to create businesses. I loved this idea, had a few side projects, and had recently discovered the startup literature that floated around the internet.</p>



<p>I had just arrived in New York only a few months before, and unknowingly, after reading a series of <a href="https://news.ycombinator.com/">Hacker News</a> posts and writing from <a href="http://www.paulgraham.com/articles.html">Paul Graham</a>, I was convinced that doing something in the startup space is my calling, but didn‚Äôt know exactly how or what to do. As I was establishing my career, I thought Gary Chou was the East Coast Asian Paul Graham.</p>



<div class="wp-block-image"><figure class="alignleft is-resized"><img loading="lazy" decoding="async" src="/wp-content/uploads/2020/03/img_5e65c0cb5f311.png" alt="" width="332" height="163"><figcaption>Do you see the resemblance?</figcaption></figure></div>



<p>Before making that connection, I also was trying to figure out what was wrong with Gary. I couldn‚Äôt quite pin how a random person would get a multi-year lease on a three story New York city building, with no particular business plan. Very Gary.</p>



<p>I have incredible appreciation for Orbital and the immeasurable effort Gary and the others put into building the community.&nbsp;</p>



<p>A random list of things that I won‚Äôt forget and give me great joy to think about.</p>



<ul class="wp-block-list"><li>155 Rivington has a (and hopefully will continue to have) historic piece of punk rock graffiti. Not only, it was also used for a Rancid music video and the graffiti piece itself has been there since.</li></ul>



<div class="wp-block-image"><figure class="alignleft is-resized"><img loading="lazy" decoding="async" src="/wp-content/uploads/2020/03/img_5e65c0cdc12d0.png" alt="" width="267" height="199"><figcaption>http://fredbenenson.com/2014/01/19/digital-forensics-rancid-reas-kickstarter-hq/</figcaption></figure></div>



<ul class="wp-block-list"><li>For the last two years, I considered trying to figure out how to plan a wedding in New York. I kept thinking Orbital was the perfect kind of place to do that. My wife and I ended up not going that route. But someone did! Proof 155 Rivington isn‚Äôt just a coworking space. Who gets married in a coworking space?¬†<br><br>
</li></ul>



<div class="wp-block-image"><figure class="alignright is-resized"><img loading="lazy" decoding="async" src="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.53-PM-1024x788.png" alt="" class="wp-image-1002" width="334" height="256" srcset="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.53-PM-1024x788.png 1024w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.53-PM-300x231.png 300w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.53-PM-768x591.png 768w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.06.53-PM.png 1687w" sizes="auto, (max-width: 334px) 100vw, 334px"><figcaption>Thats Kevin, but you get the idea.</figcaption></figure></div>



<ul class="wp-block-list">
<li>My first VR experience was at Orbital. Orbital attracted people with a wide range of interests. Of course, some of those were in deep technology. One member, <a href="https://twitter.com/shacheng">Shawn Cheng</a>, who was passing through the space when I was there had a passion for helping people experience their first major VR experience. For me, that was <a href="https://www.oculus.com/experiences/rift/1052821828143109/?locale=en_US">Kingspray</a>, the VR version of spray painting on a wall. Surprisingly, it was amazing and I spent well over an hour ‚Äúspray painting‚Äù a mural. Where else can you take a break from working and get up to spray paint a VR mural?¬†<br>
</li>
<li>I remember also with Shawn (VR guy mentioned above) enjoying a cigar out on the back porch of Orbital. Soon after, I was directly reprimanded for not being allowed to smoke in the back patio. Fond memories of Gary‚Äôs reprimands.¬†</li>
</ul>



<div class="wp-block-image"><figure class="alignleft is-resized"><img loading="lazy" decoding="async" src="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.07.55-PM-1024x793.png" alt="" class="wp-image-1001" width="263" height="204" srcset="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.07.55-PM-1024x793.png 1024w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.07.55-PM-300x232.png 300w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.07.55-PM-768x595.png 768w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.07.55-PM.png 1295w" sizes="auto, (max-width: 263px) 100vw, 263px"><figcaption>Shawn explaining how to navigate VR.</figcaption></figure></div>



<ul class="wp-block-list">
<li>When I realized I was interested in Machine Learning, I had the bright idea of building a computer to train ML models. Gary let me use the space to ship computer parts, build a computer, and also for quite a while he also let me house the machine for free. This was around the crypto craze, so I strongly believed that Gary thought I was mining bitcoin. (I wasn‚Äôt mining crypto Gary. I promise.) It speaks to his willingness to support others.<br>
</li>
<li>I remember I would spend weekends and late nights at Orbital. One late night &#8211; I think it was a Saturday &#8211; the bar downstairs was pumping some kind of club music and I was on the second floor piecing together the desktop computer parts that had finally arrived. It was almost midnight and I was convinced I was going to be alone until I closed up, and surprise &#8211; two Orbital members showed up with suitcases &#8211; arriving from a recent trip. It was an odd exchange &#8211; me with a huge table full of computer parts &#8211; and them not expecting to see anyone so late in the evening.</li>
</ul>



<figure class="wp-block-image alignwide"><img loading="lazy" decoding="async" width="1024" height="759" src="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.05.51-PM-1024x759.png" alt="" class="wp-image-1000" srcset="/wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.05.51-PM-1024x759.png 1024w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.05.51-PM-300x222.png 300w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.05.51-PM-768x569.png 768w, /wp-content/uploads/2019/12/Screen-Shot-2019-12-06-at-1.05.51-PM.png 1753w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>Setting up a deep learning machine December 2017</figcaption></figure>



<ul class="wp-block-list">
<li>At one point Orbital didn‚Äôt have any air conditioning (or if it did there was really old). I remember arriving to 155 one day and seeing a stack of 6-8 air conditioning units that were donated. It was an odd sight that I still remember vividly for some reason.<br>
</li>
<li>July 4th, I remember watching fireworks by the river from the roof. I don‚Äôt remember exactly why, but I remember spending time on the roof for a number of other occasions as well.<br>
</li>
<li>Orbital is a physical space, but somehow I keep encountering Orbital people in digital space. One odd experience was when I posted in a private <a href="https://www.facebook.com/groups/onewheelownersgroup/">Facebook group for OneWheel owners</a> and a response came from <a href="https://www.linkedin.com/in/michaelwma/">Mike Ma</a>, an Orbital member who happened to also ride OneWheels. That led to a number of fun excursions riding around Prospect Park and the Cloisters.</li>
</ul>



<p>Beyond the random list, I came to New York not having any roots, and eventually shifted toward making incredible friends and collaborators. Much of that stemmed and came back around to Orbital. My last three jobs were all related directly or indirectly to Gary and Orbital. My current job contracting with Google, I got through a relationship that I created from the Bootcamp &#8211; when Gary encouraged us to meet people who are ‚Äúexperts‚Äù &#8211; and also directly from the #jobs channel in the Orbital Slack. The job before, was a ‚Äúpivot‚Äù for me, where I worked at a machine learning focused company. Gary encouraged me to take time to write out exactly what I wanted to do, what my path was up to now, and explain where I wanted to be. By going through that exercise, it became clear how I could get the kind of job in an industry I was interested in, while also being able to articulate my value to someone. And before that, I worked in the federal government, where I was encouraged through being around so many Orbital members, to do something that was more than just a paycheck. The search for something that was meaningful and contributive to the people I worked with was what made me think I would even consider the opportunity.</p>



<p>In other words, thank you Gary for everything you put together, all the financial hurdles you jumped through to make 155 possible, and the unending love you put into making Orbital so special.</p>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span class="entry-tags">Tagged With: <a href="/tag/orbital/" rel="tag">orbital</a>, <a href="/tag/reflection/" rel="tag">reflection</a></span></p></footer></article><article class="post-741 post type-post status-publish format-standard has-post-thumbnail category-uncategorized tag-machine-learning tag-rails tag-react tag-react-native tag-street-art entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/03/07/how-public-art-works/">How Public Art works</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-03-07T15:40:38+00:00">March 7, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<h4>Details on my React-Native iOS application backed by a Ruby on Rails backend and some Python Jupyter notebook¬†scripts</h4>
<h3>Public Art is an iOS application that helps you discover new nearby street¬†art.</h3>
<p>I‚Äôve been working on this project on my own, but it has a lot of technical moving parts. I will explain how all of the moving parts work and what I‚Äôm planning to do in the near future. By the end of this article, I hope you have the awareness of recreating the same behavior for your own project.</p>
<h4>Background</h4>
<p>First of all, the reason I am working on a street app discovery tool is not to build the next urban media empire.</p>
<p>Although that sounds nice. I started trying to preserve graffiti and street art with as much associated metadata as possible for future art connoisseurs.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="1316" data-height="1366" src="/wp-content/uploads/2020/03/1GyBHw-rmrgGRYL4xqiSCSg.png"><figcaption class="wp-caption-text">At one time I was trying to make a street art media empire, through questions. I wrote a series of fragmented blog posts in 2013, that later grew into this. Most of the posts can still be found here: <a href="http://newpublicartfoundation.com/" target="_blank" rel="noopener noreferrer">http://newpublicartfoundation.com/</a></figcaption></p></figure>
<p>Given the rate at which photos are uploaded online, I felt it would be a great opportunity to preserve the otherwise transient form of cultural expression that is found around the world. I don‚Äôt have a secret surveillance agenda or political motive. I understand the privacy implications of preserving this information, as well as the complicated legal potholes involved.</p>
<p>That all being the case, I feel it‚Äôs important that someone preserves street art for the future, and that‚Äôs what I‚Äôll go into below.</p>
<h4>Frontend</h4>
<p>The front-end portion of Public Art is a mix of an Expo based React Native application with a few interspersed Ruby on Rails and React web pages. The React Native application is a stock Expo application with a modern Redux/React Navigation architecture.</p>
<p>Beyond Redux and React Navigation, I used a number of packages to help with speeding up development. I used a UI library called NativeBase which provides some helper components, but eventually transitioned to using React Native Elements. Both of these libraries were not necessary, but provided enough structure to speed up my process. The main tool needed in any good UI library is a good layout structure. For React Native, the most common layout technique I saw was to use flexbox.</p>
<p>The app is composed of primarily loading images and displaying mapped points. I initially tried to use a few helper libraries for gracefully loading images, but eventually found the best performance around using the React Native Image tag as is.</p>
<figure>
<p><img decoding="async" data-width="1600" data-height="1200" src="/wp-content/uploads/2020/03/1iC8vg624h5K6cy4lphCuEw.jpg"><br>
</p></figure>
<p>For the map, I depended on the Expo framework‚Äôs React Native Maps integration. I explored ways to use Mapbox, but to stay within the Expo ecosystem, decided not to. That being said, the React Native Maps is a great library with all of the application control needed highly responsive maps.</p>
<p>As mentioned above, I used Redux for the primary datastore of the app. For managing the application‚Äôs side effects, I decided to use Redux Saga. In the past few React applications I‚Äôve built, I aired on the side of using Redux Thunks. I noticed in my last project that the ability to test Thunks was overly complicated and wanted to pursue a more testable solution. After some research, I decided the best bet was Redux Saga. While this took getting used to, I do see the value and intuitive nature of the Saga based datastore/side effect architecture.</p>
<h4>Backend</h4>
<p>The back-end of Public Art is a combination of a few different ‚Äúmicro services‚Äù. In other words, it‚Äôs composed of a few web applications that talk to each other over http requests. In addition, I have a linux box that runs a series of shell scripts and cron jobs that provide important functionality that will eventually be replaced with another ‚Äúservice‚Äù.</p>
<figure>
<p><img decoding="async" data-width="1394" data-height="1596" src="/wp-content/uploads/2020/03/1iznMJvK56HAVNCD9-SRXsA.png"><br>
</p></figure>
<p>The primary backend and authentication works as a Ruby on Rails application running a few gems which I‚Äôll explain below. The Rails app runs on Heroku and uses the Heroku Postgres and Redis hosted services. While this is a costlier way to operate (especially because I have free credits in two different hosting providers), the convenience really makes a difference. It‚Äôs easy to deploy, manage credentials, and spin up/down workers.</p>
<p>For authentication management, I use the ruby gem Devise. Devise is a familiar gem for any Rails developer that needs any kind of user profile/authentication system. In my case, the Devise instance is setup with a User model, but all the views and business logic is triggered with a token based REST api. This was tricker to get setup than expected, but eventually became the most flexible way to control user activity.</p>
<p>For image uploads, I use the ruby gem Shrine. Shrine is a modern implementation of some other common image management gems like Carrierwave, Paperclip, and Refile. The Shrine gem plugs into Amazon‚Äôs S3 and creates a simple means of caching image display formats for easy use.</p>
<figure>
<p><img decoding="async" data-width="1940" data-height="1028" src="/wp-content/uploads/2020/03/1qnUJMmYuFJgA_fzApKyZpA.png"><br>
</p></figure>
<p>For worker management, I use the ruby gem Sidekiq, which is a Redis job manager. Sidekiq handles all of my asynchronous actions, of which there are many.</p>
<p>Finally, for location related actions, I use the ruby gem Geocoder. Geocoder hooks into the Microsoft Bing location API to do reverse geocoding. This means taking a latitude and longitude point, and inferring a address.</p>
<p>Overall, the Ruby application handles all of the business logic for creating users, saving images, managing locations, and aggregating all of the information for the iOS frontend to display. All of this happens using various api endpoints that communicate with JSON.</p>
<h4>Data/Content</h4>
<p>The Public Art app provides a way for any individual to view street art images nearby. This is accomplished by surfacing images that are geotagged with a longitude and latitude point. The images are gathered by user uploads, which are few, and scraping Instagram, which provides many.</p>
<figure>
<p><img decoding="async" data-width="1090" data-height="1288" src="/wp-content/uploads/2020/03/1CohN_L3dQm1XXNBBEZ3e_A.png"><br>
</p></figure>
<p>The current method of dealing with this is very fragile and will be updated accordingly.</p>
<p>I have created a series of scripts that use a major image uploading platform as a datasource for discovering new images. I use the user generated categorization system to identify content that may be associated to street art or graffiti, and index the content that is associated with location metadata.</p>
<p>To manage the scraping process, I use a python script that manages rate-limits to the image service. The python script runs as a linux process on my server and stores images in the file system. Once the image and the post metadata is downloaded, the script does a second server request for the location details. The location is stored on the image as an ID and requires a second lookup to get the corresponding coordinates.</p>
<p>The downloaded images are uploaded to the Rails application and indexed accordingly through a second python script that runs in a Python Notebook. This is very unusual for any python developer, but surprisingly works very well.</p>
<p>I have a Jupyter server running on my linux machine that iterates through the scraped images, uploads them to the Public Art backend server, then prepares the location metadata and updates the corresponding images.</p>
<h4>Machine Learning</h4>
<p>Originally this project was meant to have more of a machine learning component, but getting all the other parts right has been priority. I‚Äôll be doing some stuff related to search and object detection soon. I‚Äôll also be using more model evaluation to handle flagging content that isn‚Äôt machine learning.</p>
<h4>Conclusion</h4>
<p>I‚Äôve been doing some additional experiments with ads and promotion which I‚Äôll write about some other time.</p>
<figure>
<p><img decoding="async" data-width="1600" data-height="1200" src="/wp-content/uploads/2020/03/16WCflK4jYvCKDIOSQW0Pbw.jpg"><br>
</p></figure>
<p><iframe loading="lazy" class="wp-embedded-content" sandbox="allow-scripts" security="restricted" title="Public Art Newsletter" width="100%" height="386" scrolling="no" frameborder="0" src="https://upscri.be/f/49a3a0?as_embed=true#?secret=cEMaBk93i7" data-secret="cEMaBk93i7"></iframe></p>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span class="entry-tags">Tagged With: <a href="/tag/machine-learning/" rel="tag">Machine Learning</a>, <a href="/tag/rails/" rel="tag">Rails</a>, <a href="/tag/react/" rel="tag">React</a>, <a href="/tag/react-native/" rel="tag">React Native</a>, <a href="/tag/street-art/" rel="tag">Street Art</a></span></p></footer></article><article class="post-742 post type-post status-publish format-standard category-uncategorized entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/03/05/short-announcement-app-went-out/">Short announcement: App went out.</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-03-05T07:18:29+00:00">March 5, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<h4>And I added 20,000 new photos in the last two¬†weeks</h4>
<p>Quick update to keep with the bi-weekly rhythm. This one will be shorter than others.</p>
<p><iframe loading="lazy" class="wp-embedded-content" sandbox="allow-scripts" security="restricted" title="Public Art Newsletter" width="100%" height="386" scrolling="no" frameborder="0" src="https://upscri.be/f/49a3a0?as_embed=true#?secret=GpfiGFOdVY" data-secret="GpfiGFOdVY"></iframe></p>
<p>Last email I shared background details on the iOS application I launched.</p>
<p>You can find the app on the Apple app store now here: <a href="https://itunes.apple.com/us/app/public-art/id936484924?mt=8" target="_blank" rel="noopener noreferrer">https://itunes.apple.com/us/app/public-art/id936484924?mt=8</a></p>
<p>If you have an iPhone, take a look at the ‚ÄúSearch nearby‚Äù feature to view all the street art near you.</p>
<figure>
<p><img decoding="async" data-width="1380" data-height="556" src="/wp-content/uploads/2020/03/0028huHQNWO056_1z.png"><br>
</p></figure>
<p>As mentioned in the previous emails, the app is composed of three main sections. In the ‚ÄúMap‚Äù browsing section, you can query your location and view images uploaded to Instagram that are nearby you.</p>
<p>Please let me know what you think!</p>
<p>Brief update for the last two weeks.</p>
<p>The main result of this past two weeks was bug fixing and getting the app out on the App store. I was having trouble launching due to numerous Apple app store guideline conflicts.</p>
<p>Now that it‚Äôs up, I have been working on various server related changes. I made some caching changes on the backend, so that I don‚Äôt have to worry about my location queries crashing my app. Every query is cached for 30 minutes, so major traffic wont result in downtime.</p>
<p>I set up a simple but important piece of a feature that will integrate some of the machine learning research I did before. I made a simple python server that can accept an image as a parameter, and return the image‚Äôs feature embeddings. This is going to be useful when building out a search utility for querying images based on the image content, as observed via the previously trained machine learning models.</p>
<p>You can see the open source code here: <a href="https://github.com/rememberlenny/publicart-ml-endpoint" target="_blank" rel="noopener noreferrer">https://github.com/rememberlenny/publicart-ml-endpoint</a></p>
<p>Side note: I got some Public Art logo stickers. If you would like one, send me an email and I‚Äôll ship you a few: lenny@publicart.io</p>
<p>Thanks for reading!</p>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> </p></footer></article><article class="post-743 post type-post status-publish format-standard category-uncategorized tag-machine-learning tag-public-art tag-street-art entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/02/20/weekly-update-february-19-2019/">Weekly update February 19, 2019</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-02-20T04:49:16+00:00">February 20, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<h4>Bi-weekly update for February 19th,¬†2019</h4>
<p>Hey! I promised a bi-weekly update, so heres #2!</p>
<p><iframe loading="lazy" class="wp-embedded-content" sandbox="allow-scripts" security="restricted" title="Public Art Newsletter" width="100%" height="386" scrolling="no" frameborder="0" src="https://upscri.be/f/49a3a0?as_embed=true#?secret=7ehnCe9DUH" data-secret="7ehnCe9DUH"></iframe></p>
<p>I did a lot of new development this past two weeks. To kick it off, I started experimenting with social media ads, selling physical products, built and released 21 versions of an app, majorly upgraded my backend application, and finally got the python scrape/import process working.</p>
<p>Heres the details:</p>
<p>Two weeks ago, I mentioned the progress on the machine learning tasks I was running, and I got the following message in the Pioneer August cohort.</p>
<figure>
<p><img decoding="async" data-width="1481" data-height="523" src="/wp-content/uploads/2020/03/1zvxhffODob9TORpsTJDClQ.jpg"><br>
</p></figure>
<p>In short, I was reminded that I can build a sustainable business around the art collected in this project, and was encouraged to consider what that would look like. I had previously written off the notion of selling anything, as I am more interested in the preservation of street art, but the suggestion alone got my mind racing.</p>
<figure>
<p><img decoding="async" data-width="694" data-height="912" src="/wp-content/uploads/2020/03/1cWGSBEjx2mggoBcp7aoGyg.png"><br>
</p></figure>
<p>I set up a landing page for selling street art posters, and set up a variety of social media based ads. I targeted people who are interested in street art and graffiti related hashtags, and set up a small but reasonable budget across the audiences. I noticed that a basic advertisement selling a poster for $26 got a decent. I did a very small (and unreasonable) experiment around ‚Äúfree‚Äù posters, to get a sense of how the general product was being received, vs the cost. Overall, this led to the next step.</p>
<p>I explored sourcing poster prints and found the margins of a totally hands off poster printing business to actually be very reasonable. Even with accounting for driving traffic with ads, there is a potential for building something that can generate income that could be funneled back to artists or photographers. I ordered one poster company‚Äôs print and was pleasantly surprised with the paper and print quality for the cost and photo resolution.</p>
<figure>
<p><img decoding="async" data-width="2716" data-height="1494" src="/wp-content/uploads/2020/03/1YFMcLzuZ8qwc-NxP1I0_Ww.png"><br>
</p></figure>
<p>Shifting away from the new idea, I spent a lot of effort building out the actual street art tools. Last email was about the machine learning part of training a model to detect street art. This week, I focused more on building the tool to have user-generated content, and a pleasantly medium for consuming the images.</p>
<p>I decided to fully rebuild my original iOS app that was launched in 2014. Since launching, I hadn‚Äôt touched it, and it began collecting proverbial dust.</p>
<p>I had three parts that needed to be revitalized.</p>
<p>First, I needed a new app. Second, I needed fresh content to serve. And third, I needed a way to manage the content uploaded by users.</p>
<p>Regarding the app, I have been thinking about the execution of a good street art application for a while, so I knew what I wanted to do. Rather than focusing one something that manually needs managing and updating, I knew the only way I could be effective at building something was to make a self-updating, self-engaging app that used feeds of data to refresh itself to users. I also realize that the effective street art browsing method is not a regular cadence of opening the app, but rather a semi-regular summary email/notification that draws in an interested user.</p>
<p>I decided to use React Native and built out a four part app. The first part provides an editorially curated list of images from a larger community. Each day this create a fresh set of images that can be viewed. The second part of the app is a search based tool that lets people search for images in a specific place. The specific places are most interesting if they are your current location, but given that there are so many images being uploaded daily, so the third part of the app is a tool to view trending cities. Finally, the fourth part of the app is to allow users to upload content on their own and tag/label images.</p>
<p>Demo: <a href="https://youtu.be/wRWcbB3HfDY" target="_blank" rel="noopener noreferrer">https://youtu.be/wRWcbB3HfDY</a></p>
<figure>
<p><img decoding="async" data-width="480" data-height="512" src="/wp-content/uploads/2020/03/1lfGAqvx9yxMP5lOnCHdlNA.gif"><br>
</p></figure>
<p>Based on this model, I was able to get an authentication system up and running that allows users to sign up with a digital identity. This was built around a previous application I had, so I have a way to customize the experience of a user based on their browsing history and potential create tools around the user behavior. This system also allows me to have user generated content associated to an account, which is important for a variety of reasons.</p>
<p>For the daily update content, I took a shortcut and decided to feed images from the Reddit streetart subreddit. This group regularly uploads images at a steady cadence, so for now, this is my source of editorially curated content.</p>
<p>For the location search and trending locations, I was able to use my old API for street art in my 2014 app. The server that does the calculation of your current location and the nearest images to that point is still functional. The only problem is that all the old images are no longer accessible due to instagram‚Äôs platform changes in the past. As a result, I needed to rebuild the dataset around this server.</p>
<p>To do that, I have been scraping images for the past couple months, but haven‚Äôt been able to process them accordingly to refresh the local art detecting service. To get the images ready, I needed to make a small program that checked if the scraped images had associated location data, then upload the images to my application and create a location data point to correlate to the image. This was something I kept putting off, but finally took the time to do it.</p>
<p>I ended up writing the image uploader and location metadata association script in a python notebook. Being that it was such an iterative process to get right, I surprisingly found it useful. This was very unexpected.</p>
<figure>
<p><img decoding="async" data-width="1280" data-height="1150" src="/wp-content/uploads/2020/03/1aAt8bO1UEVMYcE3jZy8HLA.png"><br>
</p></figure>
<p>I got the first batch of 10,000 images working and have many hundreds of thousands of images to process accordingly. Fortunately for the most recent batch, I scraped the images with location data. As a result, the images were slower to download, but I only had one remaining step after I was done.</p>
<p>For the remaining images, I need to add a step of checking if the downloaded images have corresponding location data. This shouldn‚Äôt take too long.</p>
<p>I have a few more possible tasks I need to figure out. One, is my image scraper saves images to a file system. The ideal situation would be to write a program that directly scrapes images and does all the other stuff needed to get the location data, and import the images into my application. Because there is so much rate limiting around the scraper, this is harder than it sounds. As a result, I need to make some kind of daemon that monitors my filesystem for new files and manages the scraped images. This daemon would ideally check which files were already checked/uploaded and then I would be able to let the scraper keep operating as it is.</p>
<p>Separately, I noticed that a lot of the newer images I have been getting have less accurate location metadata. I think this is part of the privacy/security shift on the Instagram platform. Although it‚Äôs not explicit, I imagine that the Instagram UI defaults to auto-populating locations that less specific when people are uploading images. As a result, I find that I will likely need to account for ways to properly associate images to their proper locations.</p>
<p>Lots of stuff happening and more to come!</p>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span class="entry-tags">Tagged With: <a href="/tag/machine-learning/" rel="tag">Machine Learning</a>, <a href="/tag/public-art/" rel="tag">Public Art</a>, <a href="/tag/street-art/" rel="tag">Street Art</a></span></p></footer></article><article class="post-744 post type-post status-publish format-standard category-uncategorized tag-artificial-intelligence tag-machine-learning entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/02/20/weekly-update-monday-february-4/">Weekly update Monday, February 4</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-02-20T04:46:50+00:00">February 20, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<h4>Weekly update February 4,¬†2019</h4>
<p>I will be doing my best to send a bi-weekly update on the progress around my efforts to build out a street art genealogy online, and create a tool for preserving otherwise undocumented street art.</p>
<p><iframe loading="lazy" class="wp-embedded-content" sandbox="allow-scripts" security="restricted" title="Public Art Newsletter" width="100%" height="386" scrolling="no" frameborder="0" src="https://upscri.be/f/49a3a0?as_embed=true#?secret=dB0wa0QYVN" data-secret="dB0wa0QYVN"></iframe></p>
<p>So far in 2019, I have many exciting updates:</p>
<p>* Open-sourced tools for detecting street art in images using machine learning[¬π]<br>* Published a 4000+ word article on how to train a convolutional neural network (CNN) to recognize street art in location tagged photos online.[¬≤]<br>* Released a dataset of 6000 street art images and non-street art New York City images for CNN training.[¬≥]<br>* Met with authors of three street art discovery/preservation apps [‚Å¥]<br>* Presented the Public Art project and model training process at BetaWorks</p>
<p>I have been focusing on three major parts of this project: image collection, data analysis, and presentation.</p>
<p>For the image collection, I have continued to use Instagram scraping as the primary source for new images. Currently, this method has been effective for quickly gathering data to train deep learning models, but does not offer a long term solution for image aggregation. I have noticed a few times already that the primary methods for image collection have been shut down. Although I know this to be the case, I am able to gather hundreds of thousands of newly uploaded images a week, which is incomparable to any alternative user generated methods.</p>
<p>For data analysis, I have been analyzing images with associated location metadata by training deep learning models around artists and street art types (stencils, murals, letterform). I have also spent a lot of time with python notebooks, trying to find trends in certain periods of scraped images. I have been experimenting with ‚Äúhot spot‚Äù detection based on images photographed in an specific area in a small amount of time. For example, detecting when new images are found from multiple people within a smaller frequency than previously found.</p>
<p>Finally, for presentation, I have been working on two methods: website and email newsletter. For the website, I have fortunately been able to quickly build out a web interface for loading and navigating images, but do not feel that the current methods fulfill my original intention of the project. As a result, I have not publically released any updates on this front.</p>
<p>For the newsletter, I have created a set of tools to determine if ‚Äúnew‚Äù street art is discovered in a place. Currently, I manually run 4 of python scripts to based on monitoring new images found from certain locations. I am working on establishing a steady stream of images I can monitor, to generate a weekly newsletter of ‚Äúthe best local street art‚Äù for respective interested subscribers.</p>
<p>I have been recently encouraged to consider the larger vision around the Public Art project. I am building out a steady infrastructure for housing and collecting street art, but do not had a plan for attracting an active audience. With the analogy of building a city, I am building a beautiful city with few inhabitants, but could develop a blossoming city as populous as Tokyo. Based on this, I will be consolidating my efforts.</p>
<p>I would appreciate thoughts around whether or not to build a healthy business around the audience interested in street art, or to follow a non-profit route. When considering the business route, I can clearly see a productization of the collected images with a high margin art, such as printed posters. The sales model around street art products offers the opportunity for driving paid traffic to the website, which would also generate traffic that would lead to user-generated image contributions. If I pursue the non-profit route, I will not have the luxury of buying growth.</p>
<p>Please send your thoughts to <a href="mailto:Lenny@publicart.io" target="_blank" rel="noopener noreferrer">Lenny@publicart.io</a>&lt;mailto:<a href="mailto:Lenny@publicart.io" target="_blank" rel="noopener noreferrer">Lenny@publicart.io</a>&gt;</p>
<p>[1]: <a href="https://github.com/rememberlenny/streetart-notstreetart" target="_blank" rel="noopener noreferrer">https://github.com/rememberlenny/streetart-notstreetart</a></p>
<p>[2]: <a href="https://blog.floydhub.com/instagram-street-art/" target="_blank" rel="noopener noreferrer">https://blog.floydhub.com/instagram-street-art/</a></p>
<p>[3]: <a href="https://www.floydhub.com/rememberlenny/datasets/streetart-notstreetart/3" target="_blank" rel="noopener noreferrer">https://www.floydhub.com/rememberlenny/datasets/streetart-notstreetart/3</a></p>
<p>[4]: <a href="https://www.canvsart.com/" target="_blank" rel="noopener noreferrer">https://www.canvsart.com/</a> &amp; <a href="https://artpigeon.nyc/" target="_blank" rel="noopener noreferrer">https://artpigeon.nyc/</a></p>
<p>[5]: <a href="https://betaworks-studios.com/" target="_blank" rel="noopener noreferrer">https://betaworks-studios.com</a></p>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span class="entry-tags">Tagged With: <a href="/tag/artificial-intelligence/" rel="tag">Artificial Intelligence</a>, <a href="/tag/machine-learning/" rel="tag">Machine Learning</a></span></p></footer></article><article class="post-745 post type-post status-publish format-standard category-uncategorized tag-deep-learning tag-digital-humanities tag-instagram-marketing tag-machine-learning tag-street-art entry" itemscope itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="/2019/02/13/on-building-an-instagram-street-art-dataset-and-detection-model/">On Building an Instagram Street Art Dataset and Detection Model</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-02-13T17:30:11+00:00">February 13, 2019</time> by <span class="entry-author" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="/author/lkbgift/" class="entry-author-link" rel="author" itemprop="url"><span class="entry-author-name" itemprop="name">rememberlenny</span></a></span>  </p></header><div class="entry-content" itemprop="text">
<figure>
<p><img decoding="async" data-width="800" data-height="800" src="/wp-content/uploads/2020/03/0M1anIGwxee4055MT.png"><br>
</p></figure>
<p>What if you could pump all of the Instagram photos of Banksy‚Äôs artwork into a program that could pinpoint where the next one‚Äôs likely to be?</p>
<p>Well, we aren‚Äôt there <em>quite</em> <em>yet</em>, but there‚Äôs still some really cool stuff you can accomplish using image analysis and machine learning to better understand street art.</p>
<p>You <em>can</em> use machine learning models to detect whether an Instagram photo contains street art‚Ää‚Äî‚Ääeven classify the type of street art. For example, you can make a classifier for stencil art, letterform, portrait murals, or mixed medium installations.</p>
<p>In this article, I will go over how to build a deep learning model using TensorFlow and Keras that accomplishes the task of generally detecting street art by using publicly available social media data on Instagram.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="863" data-height="867" src="/wp-content/uploads/2020/03/0zNJPRSbPDNdd0TEm.png"><figcaption class="wp-caption-text">Results from the first version of my model. Notice that there are number of false positives. We‚Äôll improve this later by cleaning up our respective datasets.</figcaption></p></figure>
<p>To my knowledge, there isn‚Äôt a publicly available dataset of street art or graffiti. But we‚Äôll go over a few simple techniques for creating datasets from publicly available images on the Internet and social media‚Ää‚Äî‚Ääwhich will soon become indispensable tools in your machine learning toolkit. After reading this article, you‚Äôll be able to leverage these methods to generate your own datasets for anything you need.</p>
<p>We‚Äôll also learn how to build a TensorFlow model using Keras trained on our street art dataset. Then we will use this deep learning model to detect if new images contain street art photos.</p>
<blockquote><p><em>Just pick an Instagram hashtag, grab some images, and train your deep learning model.</em></p></blockquote>
<p>In the future, nearly everything will be photographed, and indirectly analyzable with machine learning. Learning how to train models to analyze this content yourself and understand the results is a superpower worth cultivating.</p>
<h3>Overview of our Instagram street art dataset and¬†model</h3>
<p>Here‚Äôs a quick overview of our process:</p>
<ol>
<li>Build a street art deep learning image dataset using hashtag results for <code>#streetart</code>
</li>
<li>Use the images to build a deep learning model that will predict if images contain street art</li>
<li>Clean the dataset and retrain the model for improved results</li>
</ol>
<p>We‚Äôll follow these three steps to build a real functioning model for classifying street art.The model here is based on the <a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener noreferrer">‚ÄúDeep Residual Learning for Image Recognition‚Äù (2015)</a> paper‚Äôs ResNet model and can be duplicated using other architectures.</p>
<p>You can view the finalized codebase in this <a href="https://github.com/rememberlenny/streetart-notstreetart" target="_blank" rel="noopener noreferrer">Github repository</a>. You can also open up the codebase (including the datasets I‚Äôve collected) on <a href="https://www.floydhub.com/" target="_blank" rel="noopener noreferrer">FloydHub</a> in a JupyterLab Workspace by clicking this button:</p>
<h3>Building the image¬†dataset</h3>
<p>Let‚Äôs recap our goal. We want to build a TensorFlow deep learning model that will detect street art from a feed of random images. We will start will pulling hash-tagged images that offer a good preliminary dataset of <em>street art</em>. Then, we will use the same method for pulling images to train against that is <em>not street art</em>, but may resemble the images that we will encounter. Using the two sets of images, we will train our model and be able to classify whether images do or don‚Äôt contain street art.</p>
<p>The Internet is full of places to gather data to train models. If you are looking for specific images, Google image searches offer an unbeatable way to get numerous images one a single subject. PyImageSearch provides an <a href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/" target="_blank" rel="noopener noreferrer">excellent guide</a> on building a deep learning dataset using Google images.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="1200" data-height="878" src="/wp-content/uploads/2020/03/0l32GZS7pg5Fhgsat.png"><figcaption class="wp-caption-text">Street art results from Google¬†images</figcaption></p></figure>
<p>Although the Google results method is straight forward, we want to emulate the process of building a model from social media data. As a result, we will train directly on the data source of choice: <a href="https://www.instagram.com/" target="_blank" rel="noopener noreferrer">Instagram</a>.</p>
<p>The same method discussed in the blog post linked above could be used for us. Simply load up Instagram‚Äôs web interface, search for the terms you want, then download all the images loaded in the browser.</p>
<p>We will go about it a little differently, in that we will use a library that simulates this process for us. While the method discussed below in one way to accomplish this, it is far from the only way.</p>
<p>If you want to skip downloading the street art images yourself, and just download a sample dataset, then skip to the next section titled: ‚ÄúPrepare your dataset‚Äù.</p>
<h3>Getting street art¬†images</h3>
<p>We will be using a Python library called Instaloader that provides an easy interface for setting a hashtag or location point. In the process, it will use the rate-limited interval and download images needed to train our model.</p>
<p><em>Details of the library can be found here: </em><a href="https://instaloader.github.io/" target="_blank" rel="noopener noreferrer"><em>https://instaloader.github.io</em></a></p>
<p>Let‚Äôs start by setting up our Python environment and installing instaloader.</p>
<p><code>pip install instaloader</code></p>
<p>Thats all we need to get our library working. Next we will get our own street art image dataset for training our model. The instaloader library will do the command line command below:</p>
<p><code>$ instaloader --no-videos --no-metadata-json --no-captions "#streetart"</code></p>
<p>This command can be better understood by reviewing <a href="https://instaloader.github.io/cli-options.html" target="_blank" rel="noopener noreferrer">the instaloader docs</a>:</p>
<figure>
<p><img decoding="async" data-width="806" data-height="456" src="/wp-content/uploads/2020/03/0Wd5QfA-xOdgOkLFp.png"><br>
</p></figure>
<p>In short, we will be downloading images that have the hashtag ‚Äústreetart‚Äù. We don‚Äôt want to download videos. The instaloader library will download the image‚Äôs caption data and metadata by default, so we also pass flags to prevent this.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="2600" data-height="1303" src="/wp-content/uploads/2020/03/0EZx3jLlxVabjcRXP.png"><figcaption class="wp-caption-text">Example of images gathered to help train our street art deep learning¬†model</figcaption></p></figure>
<p>In an alternative use case, we could also download the metadata associated with each image to collect the image‚Äôs respective longitude and latitude points. This would allow us to associate images with a specific location. Not all images have this metadata, but the downloaded data is still a good start. Definitely something that‚Äôs worth exploring in a future project!</p>
<p>Once the command above runs, you will see the command slowly downloading images into a newly created folder called <code>/#streetart</code>. Once you have enough images (approximately 1000 is a good base), then you can stop the command.</p>
<h3>Getting images to compare¬†against</h3>
<figure>
<p><img decoding="async" data-width="2116" data-height="1594" src="/wp-content/uploads/2020/03/00Ekco1g16SiX4SDf.png"><br>
</p></figure>
<p>Next, we need to download images that are not street art related. This dataset will determine the environment in which our model will perform best. If we train against a series of identical types of images, such as pictures of cats or dogs, then our model will not be refined when deployed in a production environment.</p>
<p>In our hypothetical final case, we would like our model to perform well when classifying images from a location feed, so we will pull images from a city: New York. This will also be helpful as our models trains, because the image set from New York will contain content that will help the model differentiate certain urban subjects from the street art content.</p>
<p><em>Please note, when you use the method above, you will get a wide range of images. </em><strong><em>Due to forces beyond our control, some of these images may be not safe for work. </em></strong>üò¨</p>
<p>To download images for a specific location, you must first find the location‚Äôs id. To find this, you can log into the Instagram web interface and do a search for the location you want. The URL will populate with the location‚Äôs ID, as seen below:</p>
<p><code><a href="https://www.instagram.com/explore/locations/212988663/new-york-new-york/" target="_blank" rel="noopener noreferrer">https://www.instagram.com/explore/locations/212988663/new-york-new-york/</a></code></p>
<p>As seen in the URL above, the New York location id is: <strong>212988663</strong>. Using this location id, now initiate a new instaloader query:</p>
<p><code>$ instaloader --no-videos --no-metadata-json --no-captions "%212988663"</code></p>
<figure>
<p><img decoding="async" data-width="802" data-height="348" src="/wp-content/uploads/2020/03/03c5DpcnbWLoe6ICN.png"><br>
</p></figure>
<p>Similar to before, the command above will download images from the location id of choice, without any extra files. Let this process run for as long as you ran the previous command, so you have an even number of images in your two image sets.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="1200" data-height="600" src="/wp-content/uploads/2020/03/0llgEngAto7wjvCVH.png"><figcaption class="wp-caption-text">Example of images that we will use in our training dataset of content that is ‚Äúnot street¬†art‚Äù~</figcaption></p></figure>
<h3>Prepare your¬†dataset</h3>
<p>If you followed the instructions above, you should have two directories titled <code>/#streetart</code> or <code>/%212988663</code> respectively. First, because navigating non-alphanumeric in file names is a pain in the butt, lets rename those directories <code>/streetart</code> and <code>/not_streetart</code> respectively.</p>
<p>Now create a folder called /images and move the two folders. Your file directory should look like this:</p>
<pre><code>.<br>‚îî‚îÄ‚îÄ dataset<br>  ‚îî‚îÄ‚îÄ images<br>    ‚îú‚îÄ‚îÄ not_streetart<br>    ‚îî‚îÄ‚îÄ streetart</code></pre>
<p>If you didn‚Äôt follow the instructions above, you can download the dataset I‚Äôve already prepared from FloydHub here:</p>
<p><a href="https://www.floydhub.com/rememberlenny/datasets/streetart-notstreetart/" target="_blank" rel="noopener noreferrer">https://www.floydhub.com/rememberlenny/datasets/streetart-notstreetart/</a></p>
<p>You can also run the corresponding Python notebook in a <a href="https://www.floydhub.com/run?template=https://github.com/rememberlenny/streetart-notstreetart" target="_blank" rel="noopener noreferrer">FloydHub Workspace</a>. This will let you easily follow along with the model training code in Jupyter Notebook workspace.</p>
<p>Now that we have our images to train with, we need a way to break them up into the proper training, validation, and test sets. We can do this with the following script pulled from Adrian Rosebrock‚Äôs build script:</p>
<p><em>Code is adapted from Rosebrock‚Äôs </em><a href="https://www.pyimagesearch.com/2018/12/03/deep-learning-and-medical-image-analysis-with-keras/" target="_blank" rel="noopener noreferrer"><em>build_dataset.py</em></a><em>:</em></p>
<pre><code>import random<br>import shutil<br>import os<br>from imutils import paths</code></pre>
<pre><code># Set up paths for original images and training/validation/test<br>ORIGINAL_IMAGES = "dataset/images"<br>TRAINING_PATH = "dataset/training"<br>VALIDATION_PATH = "dataset/validation"<br>TESTING_PATH = "dataset/testing"</code></pre>
<pre><code># Define the percentage of images used in training (80%),<br># and the amount of validation data<br>TRAINING_SPLIT = 0.8<br>VALIDATION_SPLIT = 0.1</code></pre>
<p>First we start with our imports and setting constants. <code>imutils</code> is a useful library created by Rosebrock for easy file and path manipulation.</p>
<pre><code># Access and shuffle original images<br>imagePaths = list(paths.list_images(ORIGINAL_IMAGES))<br>random.seed(42)<br>random.shuffle(imagePaths)</code></pre>
<pre><code># Compute the training and testing split<br>i = int(len(imagePaths) * TRAINING_SPLIT)<br>trainingPaths = imagePaths[:i]<br>testingPaths = imagePaths[i:]</code></pre>
<pre><code># Use part of the training data for validation<br>i = int(len(trainingPaths) * VALIDATION_SPLIT)<br>validationPaths = trainingPaths[:i]<br>trainingPaths = trainingPaths[i:]</code></pre>
<pre><code># Define the datasets<br>datasets = [<br>  ("training", trainingPaths, TRAINING_PATH),<br>  ("validation", validationPaths, VALIDATION_PATH),<br>  ("testing", testingPaths, TESTING_PATH)<br>]</code></pre>
<p>Next, we prepare our image files into the various training, validation and test sets. This allows us to have a unique set of images that are used for training and validation, then separately for testing.</p>
<pre><code>for (dType, imagePaths, baseOutput) in datasets:<br>  # If output directory doesn't exit, create it<br>  if not os.path.exists(baseOutput):<br>    os.makedirs(baseOutput)<br><br>  # Loop over the input image paths<br>  for inputPath in imagePaths:<br>    # Extract the filename of the input image along with its<br>    # corresponding class label<br>    filename = inputPath.split(os.path.sep)[-1]<br>    label = inputPath.split(os.path.sep)[-2]<br>    # Build the path to the label directory<br>    labelPath = os.path.sep.join([baseOutput, label])<br>    # If label output directory doesn't exist, create it<br>    if not os.path.exists(labelPath):<br>      os.makedirs(labelPath)</code></pre>
<pre><code>    # Construct the path to the destination image and then copy<br>    # the image itself<br>    p = os.path.sep.join([labelPath, filename])<br>    shutil.copy2(inputPath, p)</code></pre>
<p>Finally, we should copy our training, validation and testing datasets in their own respective directories.</p>
<h3>Dataset prep¬†summary</h3>
<figure>
<p><img decoding="async" data-width="468" data-height="348" src="/wp-content/uploads/2020/03/0abaD6UI635g0rDje.png"><br>
</p></figure>
<p>To summarize, the script checks for your images in <code>/dataset/images</code>, then does the following:</p>
<ol>
<li>Load all the original downloaded images into memory, and shuffle them around to be in a random order.</li>
<li>Split up the images into a following set: 80% reserved for training (10% of which will be for validation) and then the remaining 20% will be for testing.</li>
<li>Make the respective directories and move images into <code>/dataset/training</code>, <code>/dataset/validation</code>, and <code>/dataset/testing</code>.</li>
</ol>
<p><em>Note: All of your original images will stay in the </em><code>/dataset/images</code> <em>folder.</em>Once your dataset is split up, your images are ready to be used for training.</p>
<h3>Train your deep learning¬†model</h3>
<p>Now we will use our dataset to train our model. Our deep learning model will be trained using Keras with a ResNet based CNN architecture.</p>
<p>The training code below is primarily taken from lessons in the Deep Learning for Computer Vision with Python book and, as you might have already guessed at this point, the PyImageSearch blog by Adrian Rosebrock. I really enjoy his blog and can‚Äôt recommend it enough for concrete code examples and practical tutorials. As a result, much of the points below will be summary points and a link to the final code.</p>
<p><em>Code is adapted from Rosebrock‚Äôs </em><a href="https://www.pyimagesearch.com/2018/12/10/keras-save-and-load-your-deep-learning-models/" target="_blank" rel="noopener noreferrer"><em>save_dataset.py</em></a><em>, which we will call train_model.py.</em></p>
<pre><code>from keras.preprocessing.image import ImageDataGenerator<br>from keras.optimizers import SGD<br>from pyimagesearch.resnet import ResNet<br>from sklearn.metrics import classification_report<br>from imutils import paths</code></pre>
<pre><code>import numpy as np</code></pre>
<pre><code>NUM_EPOCHS = 30<br>BATCH_SIZE = 32</code></pre>
<pre><code>TRAINING_PATH = "dataset/training"<br>VALIDATION_PATH = "dataset/validation"<br>TESTING_PATH = "dataset/testing"<br>MODEL_NAME = "streetart_classifer.model"</code></pre>
<pre><code># Determine the total number of image paths in training, validation,<br># and testing directories<br>totalTrain = len(list(paths.list_images(TRAINING_PATH)))<br>totalVal = len(list(paths.list_images(VALIDATION_PATH)))<br>totalTest = len(list(paths.list_images(TESTING_PATH)))</code></pre>
<p>To start, we will import our dependencies and assign our constants.</p>
<p>We will be using Keras as our training library because it‚Äôs simple and provides a thorough API for our needs. The same steps could be replicated with other deep learning libraries like PyTorch and the fast.ai library. Keras provides a simple, module neural network library that can flexibly use various other machine learning frameworks as its backend. In my case, I will be using it with TensorFlow, but that shouldn‚Äôt matter. One note about Keras is it doesn‚Äôt support multi-GPU environments by default for training a network.</p>
<p>Note the <code>pyimagesearch.resnet</code> import: this is a folder containing our Keras implementation of our ResNet architecture.</p>
<pre><code># Initialize the training training data augmentation object<br>trainAug = ImageDataGenerator(<br>  rescale=1 / 255.0,<br>  rotation_range=20,<br>  zoom_range=0.05,<br>  width_shift_range=0.05,<br>  height_shift_range=0.05,<br>  shear_range=0.05,<br>  horizontal_flip=True,<br>  fill_mode="nearest")<br><br># Initialize the validation (and testing) data augmentation object<br>valAug = ImageDataGenerator(rescale=1 / 255.0)</code></pre>
<p>Unlike the <a href="http://image-net.org/index" target="_blank" rel="noopener noreferrer">ImageNet</a> or <a href="http://cocodataset.org/" target="_blank" rel="noopener noreferrer">COCO</a>, our dataset is relatively small. Because ‚Äústreet art‚Äù comes in many shapes, sizes, colors, and in a variety of environments, we will use data augmentation to help improve our training. Using the Keras image preprocessing API, we will create data augmentation objects to generate new images from our dataset with random modifications.</p>
<p>To learn more about data augmentation, see the <a href="https://keras.io/preprocessing/image/" target="_blank" rel="noopener noreferrer">Keras API</a> documentation or take a look at <a href="https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/" target="_blank" rel="noopener noreferrer">a great blog post on data augmentation</a>.</p>
<pre><code># Initialize the training generator<br>trainGen = trainAug.flow_from_directory(<br>  TRAINING_PATH,<br>  class_mode="categorical",<br>  target_size=(64, 64),<br>  color_mode="rgb",<br>  shuffle=True,<br>  batch_size=BATCH_SIZE)<br><br># Initialize the validation generator<br>valGen = valAug.flow_from_directory(<br>  VALIDATION_PATH,<br>  class_mode="categorical",<br>  target_size=(64, 64),<br>  color_mode="rgb",<br>  shuffle=False,<br>  batch_size=BATCH_SIZE)<br><br># Initialize the testing generator<br>testGen = valAug.flow_from_directory(<br>  TESTING_PATH,<br>  class_mode="categorical",<br>  target_size=(64, 64),<br>  color_mode="rgb",<br>  shuffle=False,<br>  batch_size=BATCH_SIZE)</code></pre>
<p>Once the augmentation objects are setup, we will generate the new images on the fly for our training, validation, and testing datasets.</p>
<pre><code># Initialize our Keras implementation of ResNet model and compile it<br>model = ResNet.build(64, 64, 3, 2, (2, 2, 3),<br>  (32, 64, 128, 256), reg=0.0005)<br>opt = SGD(lr=1e-1, momentum=0.9, decay=1e-1 / NUM_EPOCHS)<br>model.compile(loss="binary_crossentropy", optimizer=opt,<br>  metrics=["accuracy"])<br><br># Train our Keras model<br>H = model.fit_generator(<br>  trainGen,<br>  steps_per_epoch=totalTrain // BATCH_SIZE,<br>  validation_data=valGen,<br>  validation_steps=totalVal // BATCH_SIZE,<br>  epochs=NUM_EPOCHS)<br><br># Reset the testing generator and then use our trained model to<br># make predictions on the data<br>print("[INFO] evaluating network...")<br>testGen.reset()<br>predIdxs = model.predict_generator(testGen,<br>  steps=(totalTest // BATCH_SIZE) + 1)<br><br># For each image in the testing set we need to find the index of the<br># label with corresponding largest predicted probability<br>predIdxs = np.argmax(predIdxs, axis=1)<br># show a nicely formatted classification report<br>print(classification_report(testGen.classes, predIdxs,<br>  target_names=testGen.class_indices.keys()))</code></pre>
<p>We build, compile, and train our ResNet model using the augmented street art dataset. Our training script will make predictions on the test dataset, then index the highest probability class on each prediction.</p>
<pre><code># Save the neural network to disk<br>print("[INFO] serializing network to '{}'...".format(MODEL_NAME))<br>model.save(MODEL_NAME)</code></pre>
<p>The final results will be stored in a model named <code>streetart_classifer.model</code> which we can then deploy to classify new street art.</p>
<h3>Training summary</h3>
<p>In summary, the training script does the following:</p>
<ol>
<li>Import the various preprocessing services and helper utilities from libraries such as Keras. Also assign our constant values that we will use to access our dataset.</li>
<li>Set up data augmentation objects to prepare our small dataset for training our deep learning model.</li>
<li>Prepare our data augmentation objects to process our training, validation and testing dataset.</li>
<li>Build, compile and train our ResNet model using our augmented dataset, and store the results on each iteration.</li>
<li>Finally, save the trained model.</li>
</ol>
<h3>Using our trained street art model to classify new Instagram photos</h3>
<p>Now that you have a model that detects street art effectively, we can see how it works on real images.We will use the following code below to evaluate the model against an image, and then render the results onto the image with the OpenCV python library.</p>
<pre><code>from keras.preprocessing.image import img_to_array<br>from keras.models import load_model<br>import numpy as np<br>import random<br>import cv2<br>from imutils import build_montages<br>from IPython.display import Image</code></pre>
<p>Assuming this is a new environment, first we load our libraries. We will use the Keras <code>load_model</code> function to use our newly created model and also load in some utility libraries for testing the model on a random sets of data. One convenient utility library, <code>imutils</code> provides a function that easily renders an image montage when fed a list of images.</p>
<pre><code>MODEL_NAME = 'save_model.model'<br>MONTAGE_FILENAME = 'streetart_photo.png'<br>IMAGES_PATH = 'dataset/testing'</code></pre>
<pre><code>model = load_model(MODEL_NAME)</code></pre>
<pre><code>imagePaths = list(paths.list_images(IMAGES_PATH))<br>random.shuffle(imagePaths)<br>imagePaths = imagePaths[:1]</code></pre>
<pre><code># initialize our list of results<br>results = []</code></pre>
<p>Now we will set our constants referencing our model, rendered image name, and sample image path.</p>
<p>If we are in a Python Jupyter Notebook, we don‚Äôt need to load the model again.We will then load our test image path and randomly select an image to load. In the <code>imagePaths[:1]</code> definition, the <code>1</code> determines how many images to load, and can be increased according to the next part.</p>
<pre><code># loop over our sampled image paths<br>print("[INFO] evaluating model against test set...")<br>for p in imagePaths:<br>        # load our original input image<br>        orig = cv2.imread(p)</code></pre>
<pre><code>        # pre-process our image by converting it from BGR to RGB channel<br>        # ordering (since our Keras mdoel was trained on RGB ordering),<br>        # resize it to 64x64 pixels, and then scale the pixel intensities<br>        # to the range [0, 1]<br>        image = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)<br>        image = cv2.resize(image, (64, 64))<br>        image = image.astype("float") / 255.0</code></pre>
<pre><code>        # order channel dimensions (channels-first or channels-last)<br>        # depending on our Keras backend, then add a batch dimension to<br>        # the image<br>        image = img_to_array(image)<br>        image = np.expand_dims(image, axis=0)</code></pre>
<pre><code>        # make predictions on the input image<br>        pred = model.predict(image)<br>        print(pred)<br>        not_street_art_probability = pred.item(0)<br>        street_art_probability = pred.item(1)<br>        pred = pred.argmax(axis=1)[0]</code></pre>
<pre><code>        # an index of zero is the 'Not street art' label while an index of<br>        # one is the 'Street art found' label<br>        label = "Not street art ({0})".format(not_street_art_probability) if pred == 0 else "Street art found ({0})".format(street_art_probability)<br>        color = (255, 0, 0) if pred == 0 else (0, 255, 0)</code></pre>
<pre><code>        # resize our original input (so we can better visualize it) and<br>        # then draw the label on the image<br>        orig = cv2.resize(orig, (800, 800))<br>        cv2.putText(orig, label, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,<br>                color, 2)</code></pre>
<pre><code>        # add the output image to our list of results<br>        results.append(orig)</code></pre>
<p>We will loop over the images in our test file paths. If we only load one image, this is redundant. We load the image and invoke our model‚Äôs <code>predict</code> function to get the probability score for the image containing street art. The array we get back has the ‚ÄúNot street art‚Äù score at index zero, and ‚ÄúStreet art found‚Äù score on index one.</p>
<p>We generate a new image and apply text using OpenCV‚Äôs <code>putText</code> method. The text contains the image‚Äôs predicted label and the respective probability score.</p>
<p>Once the image is created, we append it onto the <code>results</code> array.</p>
<pre><code>montage = build_montages(results, (800, 800), (1, 1))[0]<br>cv2.imwrite(MONTAGE_FILENAME, montage)<br>img = cv2.imread(MONTAGE_FILENAME)</code></pre>
<pre><code>Image(filename=MONTAGE_FILENAME)</code></pre>
<p>Finally, we use the <code>build_montages</code> library to render the images in the <code>results</code> array to create a montage. <a href="https://www.pyimagesearch.com/2017/05/29/montages-with-opencv/" target="_blank" rel="noopener noreferrer">You can learn about the build_montages function here.</a> In our example, we are only rendering one image, but the third parameter for <code>build_montages</code> can be changed to determine the number of rows and columns of images to render from the image array source. This is what I used to make the large montage of labeled images earlier in this post.</p>
<p>For <a href="https://github.com/jrosebr1/imutils/blob/5aae9887df3dcada5f8d8fa6af0df2122ad7aaca/imutils/convenience.py#L238" target="_blank" rel="noopener noreferrer">reference</a> on using <code>build_montages</code>, you can see another example of using the <code>build_montage</code> function below:</p>
<pre><code># Example for using build_montage, and not part of the street art model evaluation<br>import cv2<br>from imutils import build_montages</code></pre>
<pre><code>IMAGES_PATH = 'dataset/testing'<br>imagePaths = list(paths.list_images(IMAGES_PATH))<br>imagePaths = imagePaths[:3]<br>img_list = []</code></pre>
<pre><code>for p in imagePaths:<br># load our original input image<br>orig = cv2.imread(p)<br>img_list.append(orig)</code></pre>
<pre><code># convert image list into a montage of 256x256 images tiled in a 3x1 montage<br>montages = build_montages(img_list, (256, 256), (3, 1))</code></pre>
<pre><code># iterate through montages and display<br>for montage in montages:<br>cv2.imshow('montage image', montage)<br>cv2.waitKey(0)</code></pre>
<p>Now back to the model evaluation.</p>
<p>We store the resulting montage as an image and then use the <code>IPython</code> helper function to render the image. If we run this script as an independent file, we could also invoke the OpenCV image display function.</p>
<p>The images below are three examples of running the model evaluation code. I ran the notebook with the code and saved the images from the notebook as a file.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="800" data-height="800" src="/wp-content/uploads/2020/03/02smkbgQlmwPVO5O.png"><figcaption class="wp-caption-text">Street art found (even though this chameleon tried to blend¬†in)</figcaption></p></figure>
<figure class="wp-caption">
<p><img decoding="async" data-width="1602" data-height="1462" src="/wp-content/uploads/2020/03/16Z7VSYtd0h66ib1FN381nA.png"><figcaption class="wp-caption-text">More notorious street art¬†found!</figcaption></p></figure>
<figure class="wp-caption">
<p><img decoding="async" data-width="1628" data-height="1256" src="/wp-content/uploads/2020/03/1W6YkaeuGZrdPfPo5uOZ4iQ.png"><figcaption class="wp-caption-text">Not street art. But, yes, adorable¬†puppy.</figcaption></p></figure>
<p>Our image classifier successfully detects street art, as seen in the two images above. Each of the images with a mural painting in the image are classified correctly.</p>
<p>When we run the same classifier against an obviously non-street art images, we receive the high probability ‚ÄúNot street art‚Äù result as well.</p>
<h3>Viewing false positives</h3>
<p>Some of the false positives from the model are images that depend on a person‚Äôs interpretation for street art. Based on the photos we trained against, photos of urban building landscapes and advertisements are incorrectly categorized.</p>
<p>In our case, this hashtag dataset is an imprecise classification system in general, since some people will tag things incorrectly or subjectively.</p>
<figure class="wp-caption">
<p><img decoding="async" data-width="800" data-height="800" src="/wp-content/uploads/2020/03/0QCV4GGCHG5LNSqHm.png"><figcaption class="wp-caption-text">False positive of a blue¬†building</figcaption></p></figure>
<h3>Improving the¬†results</h3>
<p>Based on our initial dataset of hashtag and location datasets, I got roughly 60~65% accuracy with my training results. I was training on a 1080TI NVIDIA card with a batch size of 32 and 30 epochs over an hour.</p>
<p>To significantly improve this, one concrete step to take is manually review the dataset for the <code>/dataset/images/streetart</code> and <code>/dataset/images/not_streetart</code>. By reviewing the folders content, you can manually delete the images that are incorrectly labeled. In our case, because we pull data from Instagram and are using an undependable primary marker &#8211; the hashtags &#8211; to determine our dataset, we potentially have the wrong content appearing in the street art and not street art folders.</p>
<p>Once I reviewed the original crawled images, I found many images that had the hashtag streetart, but were not actually street art related. For example, images with no street art in the photo with the hashtag <a href="https://paper.dropbox.com/?q=%23streetart" target="_blank" rel="noopener noreferrer">#streetart</a>, which pollutes the model training. Similarly, in the <code>/not_streetart</code> folder, since New York is one of the most popular places for finding street art, I found pictures from the New York City location feed that were actually of street art or graffiti. To clean up the classifier, I had to delete these photos.</p>
<h3>Cleaning the¬†dataset</h3>
<p>After cleaning up the datasets manually and running the training process again, I was able to achieve an improvement in the model to 80% accuracy. <a href="https://www.floydhub.com/rememberlenny/projects/streetart-notstreetart/3" target="_blank" rel="noopener noreferrer">You can see the run data on FloydHub here.</a> FloydHub automatically generates <a href="https://docs.floydhub.com/guides/jobs/metrics/#training-metrics" target="_blank" rel="noopener noreferrer">Training Metrics</a> charts for each job when you‚Äôre using Keras:</p>
<figure>
<p><img decoding="async" data-width="1121" data-height="476" src="/wp-content/uploads/2020/03/0hK-t3SeZFop5_zGu.png"><br>
</p></figure>
<h3>Next steps for Instagram street art¬†model</h3>
<p>This was a practical application of building your own deep learning dataset around a social media source and training a model to classify the respective subject. While street art was the subject of this post, the same techniques could be used for subject of your choosing.</p>
<p>To take this further, the images being analyzed for street art could be segmented to differentiate paintings and their backgrounds. Scene recognition models would be hugely impactful at reducing the false positives caused by various indoor artwork. Similarly, using other models such as the <a href="http://places2.csail.mit.edu/" target="_blank" rel="noopener noreferrer">PlacesCNN</a>, we could identify the ‚Äústreet art-ness‚Äù that resonates through the finalized model.</p>
<p>If you‚Äôre interested in analyzing street art, you could expand this project even further by:</p>
<ul>
<li>Get street art images labeled with the artist</li>
<li>Build a model for categorizing different kinds of street art</li>
<li>Explore the comment and image description metadata associated to the images with semantic analysis</li>
<li>Correlate the location metadata on images to find correlations or unique qualities by geography</li>
<li>Analyzed street art location data to find correlations or trends to social phenomena</li>
<li>Use the models in production to compare against live location feeds</li>
</ul>
<h4>Thanks to</h4>
<p><a href="http://https//www.floydhub.com" target="_blank" rel="noopener noreferrer">FloydHub‚Äôs</a> <a href="https://blog.floydhub.com/write-for-floydhub/" target="_blank" rel="noopener noreferrer">AI Writer program</a> and <a href="https://www.charlieharrington.com/" target="_blank" rel="noopener noreferrer">Charlie Harrington</a> for editorial support! Huge thanks to <a href="http://pyimagesearch.com/" target="_blank" rel="noopener noreferrer">Adrian Rosebrock‚Äôs blog</a> for the many code examples used. Thanks to <a href="https://marginalrevolution.com/marginalrevolution/2018/11/emergent-ventures-grant-recipients.html" target="_blank" rel="noopener noreferrer">Tyler Cowen‚Äôs Emergent Ventures</a> for grant funding to explore this project and <a href="https://pioneer.app/" target="_blank" rel="noopener noreferrer">the Pioneer Tournament</a>, led by Daniel Gross and Rishi Narang.</p>
<hr>
<h3>About Lenny</h3>
<p>Lenny is building a digital genealogy of street art at Public Art. He‚Äôs scraping the internet and making a searchable database of street art around the world. One of his project‚Äôs goals is to amplify the voice of ‚Äúprotest art‚Äù against the constraints of censorship from autocratic governments. He‚Äôs also a <a href="https://blog.floydhub.com/write-for-floydhub/" target="_blank" rel="noopener noreferrer">FloydHub AI Writer</a>.</p>
<p>You can follow along with Lenny on Twitter at <a href="https://twitter.com/rememberlenny" target="_blank" rel="noopener noreferrer">@rememberlenny</a> or his project newsletter <a href="http://publicart.io/" target="_blank" rel="noopener noreferrer">http://publicart.io</a>.</p>
<h3>Links</h3>
<ul>
<li><a href="https://github.com/rememberlenny/streetart-notstreetart" target="_blank" rel="noopener noreferrer">Complete code examples</a></li>
<li><a href="https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/" target="_blank" rel="noopener noreferrer">Building a deep learning dataset with Google Images</a></li>
<li><a href="https://instaloader.github.io/" target="_blank" rel="noopener noreferrer">Instaloader</a></li>
<li><a href="https://www.floydhub.com/rememberlenny/datasets/streetart-notstreetart" target="_blank" rel="noopener noreferrer">Prepared dataset used in this post</a></li>
<li><a href="https://www.pyimagesearch.com/2018/12/03/deep-learning-and-medical-image-analysis-with-keras/" target="_blank" rel="noopener noreferrer">PyImageSearch blog post on building a deep learning model for medical image analysis with Keras</a></li>
<li><a href="https://www.pyimagesearch.com/2018/12/10/keras-save-and-load-your-deep-learning-models/" target="_blank" rel="noopener noreferrer">PyImageSearch blog post on saving a deep learning model build with Keras</a></li>
<li><a href="https://www.pyimagesearch.com/2018/09/10/keras-tutorial-how-to-get-started-with-keras-deep-learning-and-python/" target="_blank" rel="noopener noreferrer">PyImageSearch blog post on data augmentation with Keras</a></li>
<li><a href="http://places2.csail.mit.edu/" target="_blank" rel="noopener noreferrer">PlacesCNN</a></li>
<li><a href="https://www.publicart.io/" target="_blank" rel="noopener noreferrer">Public Art</a></li>
</ul>
<h4>Originally posted on FloydHub‚Äôs AI Writer‚Äôs blog: <a href="https://blog.floydhub.com/instagram-street-art/" target="_blank" rel="noopener noreferrer">https://blog.floydhub.com/instagram-street-art/</a><br>
</h4>
</div>
<footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="/category/uncategorized/" rel="category tag">Uncategorized</a></span> <span class="entry-tags">Tagged With: <a href="/tag/deep-learning/" rel="tag">Deep Learning</a>, <a href="/tag/digital-humanities/" rel="tag">Digital Humanities</a>, <a href="/tag/instagram-marketing/" rel="tag">Instagram Marketing</a>, <a href="/tag/machine-learning/" rel="tag">Machine Learning</a>, <a href="/tag/street-art/" rel="tag">Street Art</a></span></p></footer></article><div class="archive-pagination pagination"><ul role="navigation" aria-label="Pagination">
<li class="pagination-previous"><a href="/page/2/">&#x000AB; <span class="screen-reader-text">Go to</span> Previous Page</a></li>
<li><a href="/"><span class="screen-reader-text">Go to page</span> 1</a></li>
<li><a href="/page/2/"><span class="screen-reader-text">Go to page</span> 2</a></li>
<li class="active"><a href="/page/3/" aria-label="Current page" aria-current="page"><span class="screen-reader-text">Go to page</span> 3</a></li>
<li><a href="/page/4/"><span class="screen-reader-text">Go to page</span> 4</a></li>
<li><a href="/page/5/"><span class="screen-reader-text">Go to page</span> 5</a></li>
<li class="pagination-omission">
<span class="screen-reader-text">Interim pages omitted</span> &#x02026;</li> 
<li><a href="/page/86/"><span class="screen-reader-text">Go to page</span> 86</a></li>
<li class="pagination-next"><a href="/page/4/"><span class="screen-reader-text">Go to</span> Next Page &#x000BB;</a></li>
</ul></div>
</main><aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar" itemscope itemtype="https://schema.org/WPSideBar" id="genesis-sidebar-primary"><h2 class="genesis-sidebar-title screen-reader-text">Primary Sidebar</h2>
<section id="search-2" class="widget widget_search"><div class="widget-wrap"><form class="search-form" method="get" action="/" role="search" itemprop="potentialAction" itemscope itemtype="https://schema.org/SearchAction">
<label class="search-form-label screen-reader-text" for="searchform-1">Search this website</label><input class="search-form-input" type="search" name="s" id="searchform-1" placeholder="Search this website" itemprop="query-input"><input class="search-form-submit" type="submit" value="Search"><meta content="/?s=%7Bs%7D" itemprop="target">
</form></div></section>
<section id="custom_html-2" class="widget_text widget widget_custom_html"><div class="widget_text widget-wrap"><div class="textwidget custom-html-widget"><iframe src="https://rememberlenny.substack.com/embed" width="480" height="320" style="" frameborder="0" scrolling="no"></iframe></div></div></section>

		<section id="recent-posts-2" class="widget widget_recent_entries"><div class="widget-wrap">
		<h3 class="widgettitle widget-title">Recent Posts</h3>

		<ul>
											<li>
					<a href="/2022/08/23/thoughts-on-my-33rd-birthday/">Thoughts on my 33rd birthday</a>
									</li>
											<li>
					<a href="/2021/02/13/innovation-parallels-around-trucking-and-zoom/">Second order effects of companies as content creators</a>
									</li>
											<li>
					<a href="/2020/10/10/text-rendering-stuff-most-people-might-not-know/">Text rendering stuff most people might not know</a>
									</li>
											<li>
					<a href="/2020/09/15/why-is-video-editing-so-horrible-today/">Why is video editing so horrible today?</a>
									</li>
											<li>
					<a href="/2020/09/08/making-the-variable-fonts-figma-plugin-part-1-what-is-variable-fonts-simple/">Making the variable fonts Figma plugin (part 1 &#8211; what is variable fonts [simple])</a>
									</li>
					</ul>

		</div></section>
<section id="archives-2" class="widget widget_archive"><div class="widget-wrap">
<h3 class="widgettitle widget-title">Archives</h3>

			<ul>
					<li><a href="/2022/08/">August 2022</a></li>
	<li><a href="/2021/02/">February 2021</a></li>
	<li><a href="/2020/10/">October 2020</a></li>
	<li><a href="/2020/09/">September 2020</a></li>
	<li><a href="/2020/08/">August 2020</a></li>
	<li><a href="/2019/12/">December 2019</a></li>
	<li><a href="/2019/03/">March 2019</a></li>
	<li><a href="/2019/02/">February 2019</a></li>
	<li><a href="/2018/11/">November 2018</a></li>
	<li><a href="/2018/10/">October 2018</a></li>
	<li><a href="/2018/04/">April 2018</a></li>
	<li><a href="/2018/01/">January 2018</a></li>
	<li><a href="/2017/12/">December 2017</a></li>
	<li><a href="/2017/10/">October 2017</a></li>
	<li><a href="/2017/07/">July 2017</a></li>
	<li><a href="/2017/02/">February 2017</a></li>
	<li><a href="/2017/01/">January 2017</a></li>
	<li><a href="/2016/11/">November 2016</a></li>
	<li><a href="/2016/10/">October 2016</a></li>
	<li><a href="/2016/08/">August 2016</a></li>
	<li><a href="/2016/05/">May 2016</a></li>
	<li><a href="/2016/03/">March 2016</a></li>
	<li><a href="/2015/11/">November 2015</a></li>
	<li><a href="/2015/10/">October 2015</a></li>
	<li><a href="/2015/09/">September 2015</a></li>
	<li><a href="/2015/07/">July 2015</a></li>
	<li><a href="/2015/06/">June 2015</a></li>
	<li><a href="/2015/05/">May 2015</a></li>
	<li><a href="/2015/03/">March 2015</a></li>
	<li><a href="/2015/02/">February 2015</a></li>
	<li><a href="/2015/01/">January 2015</a></li>
	<li><a href="/2014/12/">December 2014</a></li>
	<li><a href="/2014/11/">November 2014</a></li>
	<li><a href="/2014/10/">October 2014</a></li>
	<li><a href="/2014/09/">September 2014</a></li>
	<li><a href="/2014/08/">August 2014</a></li>
	<li><a href="/2014/07/">July 2014</a></li>
	<li><a href="/2014/06/">June 2014</a></li>
	<li><a href="/2014/05/">May 2014</a></li>
	<li><a href="/2014/04/">April 2014</a></li>
	<li><a href="/2014/03/">March 2014</a></li>
	<li><a href="/2014/02/">February 2014</a></li>
	<li><a href="/2014/01/">January 2014</a></li>
	<li><a href="/2013/12/">December 2013</a></li>
	<li><a href="/2013/10/">October 2013</a></li>
	<li><a href="/2013/06/">June 2013</a></li>
	<li><a href="/2013/05/">May 2013</a></li>
	<li><a href="/2013/04/">April 2013</a></li>
	<li><a href="/2013/03/">March 2013</a></li>
	<li><a href="/2013/02/">February 2013</a></li>
	<li><a href="/2013/01/">January 2013</a></li>
	<li><a href="/2012/12/">December 2012</a></li>
			</ul>

			</div></section>
<section id="taxonomy_list_widget-3" class="widget widget_taxonomy_list_widget"><div class="widget-wrap">
<h3 class="widgettitle widget-title">Tags</h3>
<ul class="tlw-list" id="taxonomy_list_widget_list_3">
<li><a href="/tag/10-year-reflection/" rel="dofollow">10 year reflection (1)</a></li>
<li><a href="/tag/100-posts/" rel="dofollow">100 posts (2)</a></li>
<li><a href="/tag/2013/" rel="dofollow">2013 (1)</a></li>
<li><a href="/tag/academia/" rel="dofollow">academia (2)</a></li>
<li><a href="/tag/advertising/" rel="dofollow">Advertising (3)</a></li>
<li><a href="/tag/aging/" rel="dofollow">aging (1)</a></li>
<li><a href="/tag/agriculture/" rel="dofollow">Agriculture (1)</a></li>
<li><a href="/tag/analytics/" rel="dofollow">analytics (3)</a></li>
<li><a href="/tag/anarchy/" rel="dofollow">anarchy (1)</a></li>
<li><a href="/tag/anonymous/" rel="dofollow">anonymous (1)</a></li>
<li><a href="/tag/api/" rel="dofollow">api (1)</a></li>
<li><a href="/tag/arizona/" rel="dofollow">arizona (1)</a></li>
<li><a href="/tag/art/" rel="dofollow">Art (2)</a></li>
<li><a href="/tag/art-history/" rel="dofollow">art history (1)</a></li>
<li><a href="/tag/artfound/" rel="dofollow">artfound (1)</a></li>
<li><a href="/tag/artificial-intelligence/" rel="dofollow">Artificial Intelligence (2)</a></li>
<li><a href="/tag/balance/" rel="dofollow">balance (1)</a></li>
<li><a href="/tag/banksy/" rel="dofollow">banksy (1)</a></li>
<li><a href="/tag/beacon/" rel="dofollow">beacon (1)</a></li>
<li><a href="/tag/beacons/" rel="dofollow">Beacons (1)</a></li>
<li><a href="/tag/beast-mode-crew/" rel="dofollow">beast mode crew (2)</a></li>
<li><a href="/tag/becausewilliamshatner/" rel="dofollow">becausewilliamshatner (1)</a></li>
<li><a href="/tag/big-data/" rel="dofollow">Big Data (1)</a></li>
<li><a href="/tag/birthday/" rel="dofollow">Birthday (1)</a></li>
<li><a href="/tag/browsers/" rel="dofollow">browsers (1)</a></li>
<li><a href="/tag/buddhism/" rel="dofollow">buddhism (1)</a></li>
<li><a href="/tag/bundling-and-unbundling/" rel="dofollow">bundling and unbundling (1)</a></li>
<li><a href="/tag/china/" rel="dofollow">china (1)</a></li>
<li><a href="/tag/coding/" rel="dofollow">coding (1)</a></li>
<li><a href="/tag/coffeeshoptalk/" rel="dofollow">coffeeshoptalk (1)</a></li>
<li><a href="/tag/colonialism/" rel="dofollow">colonialism (1)</a></li>
<li><a href="/tag/communication/" rel="dofollow">Communication (1)</a></li>
<li><a href="/tag/community-development/" rel="dofollow">community development (1)</a></li>
<li><a href="/tag/computer-science/" rel="dofollow">Computer Science (1)</a></li>
<li><a href="/tag/computer-vision/" rel="dofollow">Computer Vision (6)</a></li>
<li><a href="/tag/crowdsourcing/" rel="dofollow">crowdsourcing (1)</a></li>
<li><a href="/tag/cyber-security/" rel="dofollow">cyber security (1)</a></li>
<li><a href="/tag/data-migration/" rel="dofollow">data migration (1)</a></li>
<li><a href="/tag/deep-learning/" rel="dofollow">Deep Learning (1)</a></li>
<li><a href="/tag/design/" rel="dofollow">design (1)</a></li>
<li><a href="/tag/designreflection/" rel="dofollow">designreflection (1)</a></li>
<li><a href="/tag/developer/" rel="dofollow">Developer (1)</a></li>
<li><a href="/tag/digital-humanities/" rel="dofollow">Digital Humanities (2)</a></li>
<li><a href="/tag/disruption-theory/" rel="dofollow">disruption theory (1)</a></li>
<li><a href="/tag/distributed-teams/" rel="dofollow">Distributed Teams (1)</a></li>
<li><a href="/tag/drawingwhiletalking/" rel="dofollow">drawingwhiletalking (16)</a></li>
<li><a href="/tag/education/" rel="dofollow">education (3)</a></li>
<li><a href="/tag/email-marketing/" rel="dofollow">Email Marketing (3)</a></li>
<li><a href="/tag/email-newsletter/" rel="dofollow">email newsletter (1)</a></li>
<li><a href="/tag/employee-engagement/" rel="dofollow">Employee Engagement (1)</a></li>
<li><a href="/tag/employment/" rel="dofollow">employment (2)</a></li>
<li><a href="/tag/engineering/" rel="dofollow">Engineering (1)</a></li>
<li><a href="/tag/enterprise-technology/" rel="dofollow">Enterprise Technology (1)</a></li>
<li><a href="/tag/essay/" rel="dofollow">essay (1)</a></li>
<li><a href="/tag/ethics/" rel="dofollow">Ethics (1)</a></li>
<li><a href="/tag/experiement/" rel="dofollow">experiement (1)</a></li>
<li><a href="/tag/fidgetio/" rel="dofollow">fidgetio (38)</a></li>
<li><a href="/tag/figma/" rel="dofollow">figma (2)</a></li>
<li><a href="/tag/film/" rel="dofollow">film (1)</a></li>
<li><a href="/tag/film-industry/" rel="dofollow">film industry (1)</a></li>
<li><a href="/tag/fingerpainting/" rel="dofollow">fingerpainting (8)</a></li>
<li><a href="/tag/first-1000-users/" rel="dofollow">first 1000 users (1)</a></li>
<li><a href="/tag/fonts/" rel="dofollow">fonts (1)</a></li>
<li><a href="/tag/forms-of-communication/" rel="dofollow">forms of communication (1)</a></li>
<li><a href="/tag/frontend-framework/" rel="dofollow">frontend framework (1)</a></li>
<li><a href="/tag/fundraising/" rel="dofollow">fundraising (1)</a></li>
<li><a href="/tag/future-of-journalism/" rel="dofollow">Future Of Journalism (3)</a></li>
<li><a href="/tag/future-of-media/" rel="dofollow">future of media (1)</a></li>
<li><a href="/tag/future-of-technology/" rel="dofollow">Future Of Technology (2)</a></li>
<li><a href="/tag/future-technology/" rel="dofollow">Future Technology (1)</a></li>
<li><a href="/tag/game-development/" rel="dofollow">game development (2)</a></li>
<li><a href="/tag/geospatial/" rel="dofollow">Geospatial (1)</a></li>
<li><a href="/tag/ghostio/" rel="dofollow">ghostio (1)</a></li>
<li><a href="/tag/github/" rel="dofollow">github (2)</a></li>
<li><a href="/tag/global-collaboration/" rel="dofollow">global collaboration (1)</a></li>
<li><a href="/tag/god-damn/" rel="dofollow">god damn (1)</a></li>
<li><a href="/tag/google-analytics/" rel="dofollow">google analytics (1)</a></li>
<li><a href="/tag/google-docs/" rel="dofollow">google docs (1)</a></li>
<li><a href="/tag/graffiti/" rel="dofollow">Graffiti (23)</a></li>
<li><a href="/tag/graffitifound/" rel="dofollow">graffitifound (1)</a></li>
<li><a href="/tag/graffpass/" rel="dofollow">graffpass (1)</a></li>
<li><a href="/tag/growth-hacking/" rel="dofollow">growth hacking (1)</a></li>
<li><a href="/tag/h1b-visa/" rel="dofollow">h1b visa (1)</a></li>
<li><a href="/tag/hackathon/" rel="dofollow">hackathon (1)</a></li>
<li><a href="/tag/hacking/" rel="dofollow">hacking (1)</a></li>
<li><a href="/tag/hacking-reddit/" rel="dofollow">hacking reddit (2)</a></li>
<li><a href="/tag/hardware/" rel="dofollow">Hardware (1)</a></li>
<li><a href="/tag/hiroshima/" rel="dofollow">hiroshima (1)</a></li>
<li><a href="/tag/homework/" rel="dofollow">homework (1)</a></li>
<li><a href="/tag/human-api/" rel="dofollow">human api (1)</a></li>
<li><a href="/tag/i-hate-the-term-growth-hacking/" rel="dofollow">I hate the term growth hacking (1)</a></li>
<li><a href="/tag/ie6/" rel="dofollow">ie6 (1)</a></li>
<li><a href="/tag/ifttt/" rel="dofollow">ifttt (4)</a></li>
<li><a href="/tag/image-recognition/" rel="dofollow">Image Recognition (1)</a></li>
<li><a href="/tag/immigration/" rel="dofollow">immigration (1)</a></li>
<li><a href="/tag/instagram/" rel="dofollow">instagram (1)</a></li>
<li><a href="/tag/instagram-marketing/" rel="dofollow">Instagram Marketing (1)</a></li>
<li><a href="/tag/internet-media/" rel="dofollow">internet media (1)</a></li>
<li><a href="/tag/internet-of-things/" rel="dofollow">internet of things (1)</a></li>
<li><a href="/tag/intimacy/" rel="dofollow">intimacy (1)</a></li>
<li><a href="/tag/iot/" rel="dofollow">IoT (1)</a></li>
<li><a href="/tag/iteration/" rel="dofollow">iteration (1)</a></li>
<li><a href="/tag/jason-shen/" rel="dofollow">jason shen (1)</a></li>
<li><a href="/tag/jobs/" rel="dofollow">jobs (2)</a></li>
<li><a href="/tag/jrart/" rel="dofollow">jrart (1)</a></li>
<li><a href="/tag/kickstart/" rel="dofollow">kickstart (1)</a></li>
<li><a href="/tag/king-robbo/" rel="dofollow">king robbo (1)</a></li>
<li><a href="/tag/labor-market/" rel="dofollow">labor market (1)</a></li>
<li><a href="/tag/leonard-bogdonoff/" rel="dofollow">Leonard Bogdonoff (1)</a></li>
<li><a href="/tag/literacy/" rel="dofollow">Literacy (1)</a></li>
<li><a href="/tag/location/" rel="dofollow">location (1)</a></li>
<li><a href="/tag/longform/" rel="dofollow">Longform (2)</a></li>
<li><a href="/tag/looking-back/" rel="dofollow">looking back (1)</a></li>
<li><a href="/tag/los-angeles/" rel="dofollow">los angeles (1)</a></li>
<li><a href="/tag/machine-learning/" rel="dofollow">Machine Learning (13)</a></li>
<li><a href="/tag/madewithpaper/" rel="dofollow">MadeWithPaper (106)</a></li>
<li><a href="/tag/making-games/" rel="dofollow">making games (1)</a></li>
<li><a href="/tag/management/" rel="dofollow">management (1)</a></li>
<li><a href="/tag/maps/" rel="dofollow">maps (2)</a></li>
<li><a href="/tag/marketing/" rel="dofollow">marketing (4)</a></li>
<li><a href="/tag/marketing-strategies/" rel="dofollow">Marketing Strategies (1)</a></li>
<li><a href="/tag/media/" rel="dofollow">Media (3)</a></li>
<li><a href="/tag/medium/" rel="dofollow">medium (1)</a></li>
<li><a href="/tag/mentor/" rel="dofollow">mentor (1)</a></li>
<li><a href="/tag/message/" rel="dofollow">message (1)</a></li>
<li><a href="/tag/mindmeld-games/" rel="dofollow">mindmeld games (1)</a></li>
<li><a href="/tag/mobile/" rel="dofollow">Mobile (1)</a></li>
<li><a href="/tag/music/" rel="dofollow">Music (2)</a></li>
<li><a href="/tag/music-discovery/" rel="dofollow">Music Discovery (1)</a></li>
<li><a href="/tag/neuroscience/" rel="dofollow">neuroscience (2)</a></li>
<li><a href="/tag/new-yorker/" rel="dofollow">new yorker (1)</a></li>
<li><a href="/tag/newspapers/" rel="dofollow">Newspapers (3)</a></li>
<li><a href="/tag/nomad/" rel="dofollow">nomad (1)</a></li>
<li><a href="/tag/notfootball/" rel="dofollow">notfootball (2)</a></li>
<li><a href="/tag/npaf/" rel="dofollow">npaf (1)</a></li>
<li><a href="/tag/odesk/" rel="dofollow">odesk (1)</a></li>
<li><a href="/tag/orbital/" rel="dofollow">orbital (14)</a></li>
<li><a href="/tag/orbital-2014/" rel="dofollow">orbital 2014 (14)</a></li>
<li><a href="/tag/orbital-class-1/" rel="dofollow">orbital class 1 (9)</a></li>
<li><a href="/tag/orbitalnyc/" rel="dofollow">orbitalnyc (1)</a></li>
<li><a href="/tag/paf/" rel="dofollow">paf (2)</a></li>
<li><a href="/tag/paid-retweets/" rel="dofollow">paid retweets (1)</a></li>
<li><a href="/tag/painting/" rel="dofollow">painting (1)</a></li>
<li><a href="/tag/physical-web/" rel="dofollow">physical web (1)</a></li>
<li><a href="/tag/pitching/" rel="dofollow">pitching (2)</a></li>
<li><a href="/tag/popular/" rel="dofollow">popular (1)</a></li>
<li><a href="/tag/post-production/" rel="dofollow">post production (1)</a></li>
<li><a href="/tag/privacy/" rel="dofollow">Privacy (1)</a></li>
<li><a href="/tag/process/" rel="dofollow">process (1)</a></li>
<li><a href="/tag/product/" rel="dofollow">product (1)</a></li>
<li><a href="/tag/product-development/" rel="dofollow">Product Development (2)</a></li>
<li><a href="/tag/product-market-fit/" rel="dofollow">product market fit (2)</a></li>
<li><a href="/tag/programming/" rel="dofollow">Programming (6)</a></li>
<li><a href="/tag/project-reflection/" rel="dofollow">project reflection (1)</a></li>
<li><a href="/tag/promotion/" rel="dofollow">promotion (1)</a></li>
<li><a href="/tag/prototype/" rel="dofollow">prototype (17)</a></li>
<li><a href="/tag/prototyping/" rel="dofollow">prototyping (1)</a></li>
<li><a href="/tag/public-art/" rel="dofollow">Public Art (1)</a></li>
<li><a href="/tag/public-speaking/" rel="dofollow">Public Speaking (1)</a></li>
<li><a href="/tag/publicartfound/" rel="dofollow">PublicArtFound (15)</a></li>
<li><a href="/tag/publishing/" rel="dofollow">Publishing (3)</a></li>
<li><a href="/tag/python/" rel="dofollow">Python (1)</a></li>
<li><a href="/tag/quora/" rel="dofollow">quora (1)</a></li>
<li><a href="/tag/rails/" rel="dofollow">Rails (1)</a></li>
<li><a href="/tag/react/" rel="dofollow">React (1)</a></li>
<li><a href="/tag/react-native/" rel="dofollow">React Native (1)</a></li>
<li><a href="/tag/real-design/" rel="dofollow">real design (1)</a></li>
<li><a href="/tag/recent-projects/" rel="dofollow">recent projects (1)</a></li>
<li><a href="/tag/reddit/" rel="dofollow">reddit (3)</a></li>
<li><a href="/tag/redesign/" rel="dofollow">redesign (1)</a></li>
<li><a href="/tag/reflection/" rel="dofollow">reflection (2)</a></li>
<li><a href="/tag/rememberlenny/" rel="dofollow">rememberlenny (1)</a></li>
<li><a href="/tag/remote-work/" rel="dofollow">Remote work (1)</a></li>
<li><a href="/tag/replatform/" rel="dofollow">replatform (1)</a></li>
<li><a href="/tag/responsive-emails/" rel="dofollow">Responsive Emails (1)</a></li>
<li><a href="/tag/retweet/" rel="dofollow">retweet (1)</a></li>
<li><a href="/tag/revenue-model/" rel="dofollow">revenue model (1)</a></li>
<li><a href="/tag/rick-webb/" rel="dofollow">rick webb (1)</a></li>
<li><a href="/tag/robert-putnam/" rel="dofollow">robert putnam (1)</a></li>
<li><a href="/tag/ror/" rel="dofollow">ror (1)</a></li>
<li><a href="/tag/rubyonrails/" rel="dofollow">rubyonrails (1)</a></li>
<li><a href="/tag/segmenting-audience/" rel="dofollow">segmenting audience (1)</a></li>
<li><a href="/tag/semanticweb/" rel="dofollow">Semanticweb (2)</a></li>
<li><a href="/tag/senior-meets-junior/" rel="dofollow">Senior meets junior (1)</a></li>
<li><a href="/tag/sgi/" rel="dofollow">SGI (1)</a></li>
<li><a href="/tag/side-project/" rel="dofollow">Side Project (1)</a></li>
<li><a href="/tag/sketching/" rel="dofollow">sketching (22)</a></li>
<li><a href="/tag/social-capital/" rel="dofollow">social capital (1)</a></li>
<li><a href="/tag/social-media-followers/" rel="dofollow">social media followers (2)</a></li>
<li><a href="/tag/social-media-manipulation/" rel="dofollow">social media manipulation (1)</a></li>
<li><a href="/tag/social-media-marketing/" rel="dofollow">social media marketing (1)</a></li>
<li><a href="/tag/social-reach/" rel="dofollow">social reach (5)</a></li>
<li><a href="/tag/software/" rel="dofollow">software (3)</a></li>
<li><a href="/tag/soka-education/" rel="dofollow">Soka Education (1)</a></li>
<li><a href="/tag/spatial-analysis/" rel="dofollow">Spatial Analysis (2)</a></li>
<li><a href="/tag/spotify/" rel="dofollow">spotify (1)</a></li>
<li><a href="/tag/stanford/" rel="dofollow">stanford (2)</a></li>
<li><a href="/tag/startup/" rel="dofollow">Startup (21)</a></li>
<li><a href="/tag/startups/" rel="dofollow">startups (7)</a></li>
<li><a href="/tag/stree/" rel="dofollow">stree (1)</a></li>
<li><a href="/tag/street-art/" rel="dofollow">Street Art (4)</a></li>
<li><a href="/tag/streetart/" rel="dofollow">streetart (5)</a></li>
<li><a href="/tag/stylometrics/" rel="dofollow">stylometrics (1)</a></li>
<li><a href="/tag/technology/" rel="dofollow">Technology (1)</a></li>
<li><a href="/tag/thoughts/" rel="dofollow">thoughts (1)</a></li>
<li><a href="/tag/time-as-an-asset-in-mobile-development/" rel="dofollow">Time as an asset in mobile development (1)</a></li>
<li><a href="/tag/towards-data-science/" rel="dofollow">Towards Data Science (4)</a></li>
<li><a href="/tag/trainideation/" rel="dofollow">TrainIdeation (42)</a></li>
<li><a href="/tag/travel/" rel="dofollow">travel (1)</a></li>
<li><a href="/tag/traveling/" rel="dofollow">traveling (1)</a></li>
<li><a href="/tag/tumblr-milestone/" rel="dofollow">tumblr milestone (2)</a></li>
<li><a href="/tag/twitter/" rel="dofollow">twitter (1)</a></li>
<li><a href="/tag/twitter-account/" rel="dofollow">twitter account (2)</a></li>
<li><a href="/tag/typography/" rel="dofollow">typography (2)</a></li>
<li><a href="/tag/unreal-engine/" rel="dofollow">unreal engine (1)</a></li>
<li><a href="/tag/user-behavior/" rel="dofollow">user behavior (1)</a></li>
<li><a href="/tag/user-experience/" rel="dofollow">user experience (3)</a></li>
<li><a href="/tag/user-research/" rel="dofollow">user research (1)</a></li>
<li><a href="/tag/user-testing/" rel="dofollow">user testing (1)</a></li>
<li><a href="/tag/variable-fonts/" rel="dofollow">variable fonts (1)</a></li>
<li><a href="/tag/video-editing/" rel="dofollow">video editing (2)</a></li>
<li><a href="/tag/visual-effects/" rel="dofollow">visual effects (1)</a></li>
<li><a href="/tag/warishell/" rel="dofollow">warishell (1)</a></li>
<li><a href="/tag/web-development/" rel="dofollow">Web Development (8)</a></li>
<li><a href="/tag/webdec/" rel="dofollow">webdec (1)</a></li>
<li><a href="/tag/webdev/" rel="dofollow">webdev (13)</a></li>
<li><a href="/tag/windowed-launch/" rel="dofollow">windowed launch (1)</a></li>
<li><a href="/tag/wordpress/" rel="dofollow">wordpress (1)</a></li>
<li><a href="/tag/work-culture/" rel="dofollow">Work Culture (1)</a></li>
<li><a href="/tag/workinprogress/" rel="dofollow">workinprogress (1)</a></li>
<li><a href="/tag/zoom/" rel="dofollow">zoom (1)</a></li>
</ul>
<!-- .tlw-list -->
</div></section>
</aside>
</div></div>
<footer class="site-footer" itemscope itemtype="https://schema.org/WPFooter"><div class="wrap"><p></p></div></footer>
</div>	<script type="text/javascript">function atomicBlocksShare( url, title, w, h ){
			var left = ( window.innerWidth / 2 )-( w / 2 );
			var top  = ( window.innerHeight / 2 )-( h / 2 );
			return window.open(url, title, 'toolbar=no, location=no, directories=no, status=no, menubar=no, scrollbars=no, resizable=no, copyhistory=no, width=600, height=600, top='+top+', left='+left);
		}</script>
	<style type="text/css" media="screen"></style>
<script src="/wp-content/plugins/atomic-blocks/dist/assets/js/dismiss.js?ver=1734914581" id="atomic-blocks-dismiss-js-js"></script>
<script src="https://c0.wp.com/c/6.7.1/wp-includes/js/hoverIntent.min.js" id="hoverIntent-js"></script>
<script src="/wp-content/themes/genesis/lib/js/menu/superfish.min.js?ver=1.7.10" id="superfish-js"></script>
<script src="/wp-content/themes/genesis/lib/js/menu/superfish.args.min.js?ver=3.2.1" id="superfish-args-js"></script>
<script src="/wp-content/themes/genesis/lib/js/skip-links.min.js?ver=3.2.1" id="skip-links-js"></script>
<script id="genesis-sample-responsive-menu-js-extra">var genesis_responsive_menu = {"mainMenu":"Menu","menuIconClass":"dashicons-before dashicons-menu","subMenu":"Submenu","subMenuIconClass":"dashicons-before dashicons-arrow-down-alt2","menuClasses":{"others":[".nav-primary"]}};</script>
<script src="/wp-content/themes/genesis/lib/js/menu/responsive-menus.min.js?ver=1.1.3" id="genesis-sample-responsive-menu-js"></script>
<script src="https://stats.wp.com/e-202452.js" id="jetpack-stats-js" data-wp-strategy="defer"></script>
<script id="jetpack-stats-js-after">_stq = window._stq || [];
_stq.push([ "view", JSON.parse("{\"v\":\"ext\",\"blog\":\"170131844\",\"post\":\"0\",\"tz\":\"0\",\"srv\":\"blogrememberlenny.local\"}") ]);
_stq.push([ "clickTrackerInit", "170131844", "0" ]);</script>
</body>
</html>